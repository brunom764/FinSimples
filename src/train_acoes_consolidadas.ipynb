{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e3f938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros após feature engineering: 54529\n",
      "Setores disponíveis: ['Construção' 'Industrial' 'Siderurgia' 'Alimentos' 'Energia' 'Varejo'\n",
      " 'Financeiro' 'Mineração' 'Consumo' 'Turismo' 'Celulose' 'Saúde']\n",
      "Total de registros após remoção de outliers: 44473\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's l1: 0.479005\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's l1: 0.478933\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's l1: 0.313573\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's l1: 0.313143\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's l1: 0.499935\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's l1: 0.354372\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's l1: 0.35192\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's l1: 0.245889\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's l1: 0.245712\n",
      "\n",
      "Métricas médias de validação:\n",
      "MAE: 0.3779\n",
      "RMSE: 0.5984\n",
      "R²: -0.0951\n",
      "\n",
      "Importância das features:\n",
      "feature\n",
      "sector_encoded            79813.791629\n",
      "sector_avg_volume         52387.524011\n",
      "volume_avg_21D            34677.596841\n",
      "BB_upper                  28909.775523\n",
      "SMA_200                   24017.088445\n",
      "volume_spike              20919.125553\n",
      "retorno_63D               19254.660380\n",
      "BB_lower                  17621.011434\n",
      "SMA_50                     9335.391750\n",
      "volatilidade_21D           4951.920349\n",
      "retorno_21D                1543.444051\n",
      "sector_avg_retorno_21D      993.304140\n",
      "RSI_14                      219.049815\n",
      "retorno_5D                  139.131068\n",
      "retorno_1D                    5.133040\n",
      "Name: importance, dtype: float64\n",
      "\n",
      "Modelo treinado com sucesso sem TA-Lib!\n",
      "Arquivos gerados:\n",
      "- modelo_lgbm_sem_talib.txt\n",
      "- metricas_validacao.csv\n",
      "- features_utilizadas.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Carregar e preparar os dados\n",
    "def load_data(filepath):\n",
    "    df = pd.read_csv(filepath, parse_dates=['Unnamed: 0'], index_col='Unnamed: 0')\n",
    "    df.rename(columns={'setor': 'sector'}, inplace=True)\n",
    "    df = df.sort_index()\n",
    "    return df\n",
    "\n",
    "# 2. Feature Engineering sem TA-Lib\n",
    "def create_features(df):\n",
    "    # Codificar setor como variável categórica\n",
    "    le = LabelEncoder()\n",
    "    df['sector_encoded'] = le.fit_transform(df['sector'])\n",
    "    \n",
    "    # Retornos\n",
    "    df['retorno_1D'] = df.groupby('ticker')['close'].pct_change()\n",
    "    for window in [5, 21, 63, 252]:  # 1 semana, 1 mês, 3 meses, 1 ano\n",
    "        df[f'retorno_{window}D'] = df.groupby('ticker')['close'].pct_change(window)\n",
    "    \n",
    "    # Volatilidade\n",
    "    df['volatilidade_21D'] = df.groupby('ticker')['retorno_1D'].rolling(21).std().values\n",
    "    \n",
    "    # Volume\n",
    "    df['volume_avg_21D'] = df.groupby('ticker')['volume'].rolling(21).mean().values\n",
    "    df['volume_spike'] = df['volume'] / df['volume_avg_21D']\n",
    "    \n",
    "    # Médias Móveis (substituindo TA-Lib)\n",
    "    df['SMA_50'] = df.groupby('ticker')['close'].rolling(50).mean().values\n",
    "    df['SMA_200'] = df.groupby('ticker')['close'].rolling(200).mean().values\n",
    "    \n",
    "    # RSI (implementação manual simplificada)\n",
    "    def calculate_rsi(series, window=14):\n",
    "        delta = series.diff()\n",
    "        gain = delta.where(delta > 0, 0)\n",
    "        loss = -delta.where(delta < 0, 0)\n",
    "        \n",
    "        avg_gain = gain.rolling(window).mean()\n",
    "        avg_loss = loss.rolling(window).mean()\n",
    "        \n",
    "        rs = avg_gain / avg_loss\n",
    "        return 100 - (100 / (1 + rs))\n",
    "    \n",
    "    df['RSI_14'] = df.groupby('ticker')['close'].transform(calculate_rsi)\n",
    "    \n",
    "    # Bollinger Bands (implementação manual)\n",
    "    def calculate_bollinger_bands(series, window=20, num_std=2):\n",
    "        sma = series.rolling(window).mean()\n",
    "        std = series.rolling(window).std()\n",
    "        upper = sma + (std * num_std)\n",
    "        lower = sma - (std * num_std)\n",
    "        return upper, lower\n",
    "    \n",
    "    df['BB_upper'], df['BB_lower'] = calculate_bollinger_bands(df['close'])\n",
    "    \n",
    "    # Dividendos\n",
    "    df['dividend_yield'] = df['dividend_amount'] / df['close']\n",
    "    df['dividend_payment'] = (df['dividend_amount'] > 0).astype(int)\n",
    "    \n",
    "    # Features agregadas por setor\n",
    "    df['sector_avg_retorno_21D'] = df.groupby(['sector', df.index])['retorno_21D'].transform('mean')\n",
    "    df['sector_avg_volume'] = df.groupby(['sector', df.index])['volume'].transform('mean')\n",
    "    \n",
    "    # Target: Retorno em 1 ano (252 dias úteis)\n",
    "    df['target'] = df.groupby('ticker')['adjusted_close'].transform(\n",
    "        lambda x: x.shift(-252) / x - 1\n",
    "    )\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "# 3. Tratamento de Outliers\n",
    "def remove_outliers(df, z_threshold=3):\n",
    "    # Remover outliers nas features numéricas\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numeric_cols = [col for col in numeric_cols if col not in ['target', 'split_coefficient', 'sector_encoded']]\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        z_scores = np.abs(stats.zscore(df[col]))\n",
    "        df = df[z_scores < z_threshold]\n",
    "    \n",
    "    # Remover dias com volume muito baixo (liquidez insuficiente)\n",
    "    df = df[df['volume'] > 10000]  # Ajuste conforme necessário\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "# 4. Treinamento do Modelo\n",
    "def train_model(df):\n",
    "    # Features e target\n",
    "    features = ['retorno_1D', 'retorno_5D', 'retorno_21D', 'retorno_63D',\n",
    "                'volatilidade_21D', 'volume_avg_21D', 'volume_spike',\n",
    "                'RSI_14', 'SMA_50', 'SMA_200', 'BB_upper', 'BB_lower',\n",
    "                'dividend_yield', 'dividend_payment',\n",
    "                'sector_encoded', 'sector_avg_retorno_21D', 'sector_avg_volume']\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df['target']\n",
    "    \n",
    "    # Cross-validation temporal\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    # Configuração do modelo\n",
    "    params = {\n",
    "        'objective': 'mae',\n",
    "        'num_iterations': 1000,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 7,\n",
    "        'num_leaves': 31,\n",
    "        'random_state': 42,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    \n",
    "    metrics = []\n",
    "    feature_importances = pd.DataFrame()\n",
    "    models = []  # Para armazenar todos os modelos\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        valid_data = lgb.Dataset(X_test, label=y_test)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[valid_data],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=50),\n",
    "                lgb.log_evaluation(period=100)\n",
    "            ]\n",
    "        )\n",
    "        models.append(model)  # Armazena o modelo\n",
    "        \n",
    "        # Avaliação\n",
    "        preds = model.predict(X_test)\n",
    "        metrics.append({\n",
    "            'Fold': fold + 1,\n",
    "            'MAE': mean_absolute_error(y_test, preds),\n",
    "            'RMSE': np.sqrt(mean_squared_error(y_test, preds)),\n",
    "            'R2': r2_score(y_test, preds)\n",
    "        })\n",
    "        \n",
    "        # Importância das features\n",
    "        fold_importance = pd.DataFrame({\n",
    "            'feature': features,\n",
    "            'importance': model.feature_importance(importance_type='gain'),\n",
    "            'fold': fold + 1\n",
    "        })\n",
    "        feature_importances = pd.concat([feature_importances, fold_importance])\n",
    "    \n",
    "    # Métricas médias\n",
    "    avg_metrics = pd.DataFrame(metrics).mean()\n",
    "    print(\"\\nMétricas médias de validação:\")\n",
    "    print(f\"MAE: {avg_metrics['MAE']:.4f}\")\n",
    "    print(f\"RMSE: {avg_metrics['RMSE']:.4f}\")\n",
    "    print(f\"R²: {avg_metrics['R2']:.4f}\")\n",
    "    \n",
    "    # Analisar importância das features\n",
    "    mean_importance = feature_importances.groupby('feature')['importance'].mean().sort_values(ascending=False)\n",
    "    print(\"\\nImportância das features:\")\n",
    "    print(mean_importance.head(15))\n",
    "    \n",
    "    return models[-1], features, pd.DataFrame(metrics)  # Retorna o último modelo treinado\n",
    "\n",
    "# Pipeline completo ajustado\n",
    "if __name__ == \"__main__\":\n",
    "    # Carregar dados\n",
    "    df = load_data('datasets/acoes_consolidadas.csv')\n",
    "    \n",
    "    # Criar features\n",
    "    df = create_features(df)\n",
    "    print(f\"Total de registros após feature engineering: {len(df)}\")\n",
    "    print(f\"Setores disponíveis: {df['sector'].unique()}\")\n",
    "    \n",
    "    # Remover outliers\n",
    "    df = remove_outliers(df)\n",
    "    print(f\"Total de registros após remoção de outliers: {len(df)}\")\n",
    "    \n",
    "    # Treinar modelo\n",
    "    model, features, metrics_df = train_model(df)\n",
    "    \n",
    "    # Salvar modelo e resultados\n",
    "    model.save_model('modelo_lgbm_sem_talib.txt')  # Método direto do Booster\n",
    "    metrics_df.to_csv('metricas_validacao.csv', index=False)\n",
    "    pd.Series(features).to_csv('features_utilizadas.csv', index=False)\n",
    "    \n",
    "    print(\"\\nModelo treinado com sucesso sem TA-Lib!\")\n",
    "    print(\"Arquivos gerados:\")\n",
    "    print(\"- modelo_lgbm_sem_talib.txt\")\n",
    "    print(\"- metricas_validacao.csv\")\n",
    "    print(\"- features_utilizadas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0830bbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
