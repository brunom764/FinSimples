{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f601b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando MGLU3...\n",
      "\n",
      "Features esperadas (17): ['retorno_1D', 'retorno_5D', 'retorno_21D', 'retorno_63D', 'volatilidade_21D', 'volume_avg_21D', 'volume_spike', 'RSI_14', 'SMA_50', 'SMA_200', 'BB_upper', 'BB_lower', 'dividend_yield', 'dividend_payment', 'sector_encoded', 'sector_avg_retorno_21D', 'sector_avg_volume']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\AppData\\Local\\Temp\\ipykernel_26500\\3992977878.py:17: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  dados = yf.download(ticker + '.SA', period='1y', progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Colunas disponíveis: ['date', 'close', 'high', 'low', 'open', 'volume', 'adjusted_close', 'dividend_amount', 'split_coefficient', 'ticker']\n",
      "\n",
      "Features criadas: ['retorno_1D', 'retorno_5D', 'retorno_21D', 'retorno_63D', 'volatilidade_21D', 'volume_avg_21D', 'volume_spike', 'RSI_14', 'SMA_50', 'SMA_200', 'BB_upper', 'BB_lower', 'dividend_yield', 'dividend_payment', 'sector_encoded', 'sector_avg_retorno_21D', 'sector_avg_volume']\n",
      "\n",
      "Previsão para MGLU3:\n",
      "Data: 28/07/2025\n",
      "Preço: R$7.18\n",
      "Retorno previsto: 20.91%\n",
      "Preço projetado: R$8.68\n",
      "\n",
      "Previsões salvas em 'previsoes.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "\n",
    "def corrigir_dataframe(df):\n",
    "    \"\"\"Corrige problemas com MultiIndex e garante formato consistente\"\"\"\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = df.columns.get_level_values(0)\n",
    "    return df\n",
    "\n",
    "def processar_dados(ticker):\n",
    "    \"\"\"Obtém e processa dados do Yahoo Finance\"\"\"\n",
    "    try:\n",
    "        dados = yf.download(ticker + '.SA', period='1y', progress=False)\n",
    "        dados = corrigir_dataframe(dados)\n",
    "        \n",
    "        if dados.empty:\n",
    "            raise ValueError(\"Nenhum dado obtido\")\n",
    "            \n",
    "        # Renomear colunas e garantir formato correto\n",
    "        dados = dados.rename(columns={\n",
    "            'Open': 'open',\n",
    "            'High': 'high', \n",
    "            'Low': 'low',\n",
    "            'Close': 'close',\n",
    "            'Volume': 'volume'\n",
    "        })\n",
    "        \n",
    "        # Verificar colunas essenciais\n",
    "        colunas_necessarias = ['open', 'high', 'low', 'close', 'volume']\n",
    "        if not all(col in dados.columns for col in colunas_necessarias):\n",
    "            missing = [col for col in colunas_necessarias if col not in dados.columns]\n",
    "            raise ValueError(f\"Colunas faltantes: {missing}\")\n",
    "        \n",
    "        # Adicionar colunas extras\n",
    "        dados['adjusted_close'] = dados['close'].astype(float)\n",
    "        dados['dividend_amount'] = 0.0\n",
    "        dados['split_coefficient'] = 1.0\n",
    "        dados['ticker'] = ticker + '.SA'\n",
    "        \n",
    "        return dados.reset_index().rename(columns={'Date': 'date'})\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def criar_features(dados, features_esperadas):\n",
    "    \"\"\"Cria features de forma segura e compatível\"\"\"\n",
    "    if dados is None or dados.empty:\n",
    "        return None\n",
    "        \n",
    "    df = dados.copy()\n",
    "    \n",
    "    try:\n",
    "        # 1. Corrigir formato do DataFrame\n",
    "        df = corrigir_dataframe(df)\n",
    "        \n",
    "        # 2. Features básicas\n",
    "        setores = {'PETR4.SA': 'Energia', 'VALE3.SA': 'Mineração', 'ITUB4.SA': 'Financeiro'}\n",
    "        df['sector'] = df['ticker'].map(setores)\n",
    "        le = LabelEncoder()\n",
    "        df['sector_encoded'] = le.fit_transform(df['sector'].fillna('Outros')).astype(float)\n",
    "        \n",
    "        # 3. Cálculo de retornos\n",
    "        for window in [1, 5, 21, 63]:\n",
    "            df[f'retorno_{window}D'] = df.groupby('ticker')['close'].pct_change().rolling(window).mean().values\n",
    "        \n",
    "        # 4. Volatilidade\n",
    "        df['volatilidade_21D'] = df.groupby('ticker')['retorno_1D'].rolling(21).std().values\n",
    "        \n",
    "        # 5. Volume (cálculo seguro)\n",
    "        df['volume_avg_21D'] = df.groupby('ticker')['volume'].rolling(21).mean().values\n",
    "        df['volume_spike'] = np.where(\n",
    "            df['volume_avg_21D'] > 0,\n",
    "            df['volume'] / df['volume_avg_21D'],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # 6. Features que não podem ser calculadas com 3 meses\n",
    "        for feature in ['RSI_14', 'BB_upper', 'BB_lower', 'SMA_200']:\n",
    "            if feature in features_esperadas:\n",
    "                df[feature] = 0.0\n",
    "                \n",
    "        # 7. SMA_50 (se necessário)\n",
    "        if 'SMA_50' in features_esperadas:\n",
    "            df['SMA_50'] = df.groupby('ticker')['close'].rolling(50).mean().values\n",
    "        \n",
    "        # 8. Features de dividendos\n",
    "        df['dividend_yield'] = 0.0\n",
    "        df['dividend_payment'] = 0.0\n",
    "        \n",
    "        # 9. Features de setor (simplificadas)\n",
    "        df['sector_avg_retorno_21D'] = df.groupby('sector')['retorno_21D'].transform('mean')\n",
    "        df['sector_avg_volume'] = df.groupby('sector')['volume'].transform('mean')\n",
    "        \n",
    "        # Garantir todas as features esperadas\n",
    "        for feature in features_esperadas:\n",
    "            if feature not in df.columns:\n",
    "                df[feature] = 0.0\n",
    "        \n",
    "        return df[features_esperadas]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao criar features: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def prever_acao(ticker):\n",
    "    try:\n",
    "        # 1. Carregar modelo e features\n",
    "        modelo = lgb.Booster(model_file='utils/modelo_lgbm_todas.txt')\n",
    "        features_esperadas = pd.read_csv('utils/features_utilizadas_todas.csv', header=None)[0].tolist()\n",
    "        \n",
    "        # Remover possível cabeçalho incorreto\n",
    "        if features_esperadas[0] == '0':\n",
    "            features_esperadas = features_esperadas[1:]\n",
    "        \n",
    "        print(f\"\\nFeatures esperadas ({len(features_esperadas)}): {features_esperadas}\")\n",
    "        \n",
    "        # 2. Obter dados\n",
    "        dados = processar_dados(ticker)\n",
    "        if dados is None:\n",
    "            return None\n",
    "            \n",
    "        print(\"\\nColunas disponíveis:\", dados.columns.tolist())\n",
    "        \n",
    "        # 3. Criar features\n",
    "        dados_features = criar_features(dados, features_esperadas)\n",
    "        if dados_features is None:\n",
    "            return None\n",
    "            \n",
    "        print(\"\\nFeatures criadas:\", dados_features.columns.tolist())\n",
    "        \n",
    "        # 4. Fazer previsão\n",
    "        ultimo_dia = dados_features.iloc[[-1]].values.astype(float)\n",
    "        retorno = float(modelo.predict(ultimo_dia)[0])\n",
    "        \n",
    "        # 5. Resultado\n",
    "        print(f\"\\nPrevisão para {ticker}:\")\n",
    "        print(f\"Data: {dados['date'].iloc[-1].strftime('%d/%m/%Y')}\")\n",
    "        print(f\"Preço: R${dados['close'].iloc[-1]:.2f}\")\n",
    "        print(f\"Retorno previsto: {retorno:.2%}\")\n",
    "        print(f\"Preço projetado: R${dados['close'].iloc[-1] * (1 + retorno):.2f}\")\n",
    "        \n",
    "        return retorno\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao prever {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    acoes = ['MGLU3']\n",
    "    resultados = []\n",
    "    \n",
    "    for acao in acoes:\n",
    "        print(f\"\\nProcessando {acao}...\")\n",
    "        retorno = prever_acao(acao)\n",
    "        if retorno is not None:\n",
    "            resultados.append({\n",
    "                'ticker': acao,\n",
    "                'data': datetime.now().strftime('%Y-%m-%d'),\n",
    "                'retorno_previsto': retorno,\n",
    "                'preco_atual': yf.Ticker(acao + '.SA').history(period='1d')['Close'].iloc[-1]\n",
    "            })\n",
    "    \n",
    "    if resultados:\n",
    "        pd.DataFrame(resultados).to_csv('previsoes.csv', index=False)\n",
    "        print(\"\\nPrevisões salvas em 'previsoes.csv'\")\n",
    "    else:\n",
    "        print(\"\\nNenhuma previsão concluída com sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1737b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rentabilidade anual esperada para BBDC4: -4.79%\n",
      "Status: Previsão realizada com sucesso\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import os\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Classe para extração avançada de features\"\"\"\n",
    "    def __init__(self):\n",
    "        self.features_to_use = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Garantir ordenação correta\n",
    "        if 'data_pregao' in df.columns:\n",
    "            df['data_pregao'] = pd.to_datetime(df['data_pregao'])\n",
    "            df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "        \n",
    "        # Grupo para cálculos\n",
    "        gb = df.groupby('cod_negociacao')['preco_fechamento']\n",
    "        \n",
    "        # 1. Médias móveis e volatilidade\n",
    "        for window in [4, 8, 12, 26]:\n",
    "            df[f'media_{window}w'] = gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "            df[f'vol_{window}w'] = gb.rolling(window=window).std().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # 2. Retornos protegidos contra divisão por zero\n",
    "        def safe_return(current, past, min_price=0.01):\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                return np.where(\n",
    "                    (past > min_price) & (current > min_price),\n",
    "                    (current - past) / past,\n",
    "                    np.nan\n",
    "                )\n",
    "        \n",
    "        for weeks, periods in [(1,0), (4,3), (12,11), (26,25)]:\n",
    "            preco_passado = gb.shift(periods)\n",
    "            df[f'retorno_{weeks}w'] = safe_return(df['preco_fechamento'], preco_passado)\n",
    "        \n",
    "        # 3. RSI manual (sem TA-Lib)\n",
    "        def calculate_rsi(series, window=14):\n",
    "            delta = series.diff()\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "            \n",
    "            avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
    "            avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
    "            \n",
    "            rs = avg_gain / avg_loss.replace(0, np.nan)\n",
    "            return 100 - (100 / (1 + rs.replace(np.inf, 100)))\n",
    "        \n",
    "        df['rsi_14'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(calculate_rsi)\n",
    "        \n",
    "        # 4. Features temporais\n",
    "        for lag in [1, 2, 3, 4]:\n",
    "            df[f'retorno_lag_{lag}w'] = df.groupby('cod_negociacao')['retorno_1w'].shift(lag)\n",
    "        \n",
    "        df['ema_12'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "            lambda x: x.ewm(span=12).mean()\n",
    "        )\n",
    "        \n",
    "        # 5. Features de volume\n",
    "        if 'volume' in df.columns:\n",
    "            vol_gb = df.groupby('cod_negociacao')['volume']\n",
    "            for window in [4, 12]:\n",
    "                df[f'volume_medio_{window}w'] = vol_gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # Definir features a serem usadas\n",
    "        self.features_to_use = [\n",
    "            'media_4w', 'media_12w', 'vol_4w', 'vol_12w',\n",
    "            # 'retorno_1w',\n",
    "            'retorno_4w', 'retorno_12w',\n",
    "            # 'retorno_lag_1w', 'retorno_lag_2w',\n",
    "            'volume_medio_4w', 'ema_12', 'rsi_14'\n",
    "        ]\n",
    "        \n",
    "        return df\n",
    "\n",
    "class StockPredictor:\n",
    "    def __init__(self, model, feature_extractor):\n",
    "        self.model = model\n",
    "        self.feature_extractor = feature_extractor\n",
    "    \n",
    "    def get_data_from_yfinance(self, ticker, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Obtém dados históricos do Yahoo Finance\n",
    "        \"\"\"\n",
    "        print(f\"Obtendo dados do Yahoo Finance para {ticker}...\")\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker + \".SA\")  # Adiciona .SA para ações brasileiras\n",
    "            df = stock.history(start=start_date, end=end_date)\n",
    "            \n",
    "            if df.empty:\n",
    "                raise ValueError(f\"Nenhum dado encontrado para {ticker}\")\n",
    "            \n",
    "            # Renomear colunas para corresponder ao formato esperado\n",
    "            df = df.reset_index()\n",
    "            df = df.rename(columns={\n",
    "                'Date': 'data_pregao',\n",
    "                'Close': 'preco_fechamento',\n",
    "                'Volume': 'volume'\n",
    "            })\n",
    "            \n",
    "            # Adicionar código de negociação\n",
    "            df['cod_negociacao'] = ticker\n",
    "            \n",
    "            return df[['cod_negociacao', 'data_pregao', 'preco_fechamento', 'volume']]\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao obter dados do Yahoo Finance: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def get_data_from_brapi(self, ticker, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Obtém dados históricos da Brapi.dev\n",
    "        \"\"\"\n",
    "        print(f\"Obtendo dados da Brapi.dev para {ticker}...\")\n",
    "        try:\n",
    "            url = f\"https://brapi.dev/api/quote/{ticker}?interval=1d&start={start_date}&end={end_date}\"\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            \n",
    "            if 'results' not in data or not data['results']:\n",
    "                raise ValueError(f\"Nenhum dado encontrado para {ticker}\")\n",
    "            \n",
    "            # Extrair dados históricos\n",
    "            historical_data = data['results'][0]['historicalDataPrice']\n",
    "            \n",
    "            # Converter para DataFrame\n",
    "            df = pd.DataFrame(historical_data)\n",
    "            \n",
    "            # Converter timestamp para data\n",
    "            df['data_pregao'] = pd.to_datetime(df['date'], unit='s').dt.date\n",
    "            \n",
    "            # Renomear colunas\n",
    "            df = df.rename(columns={\n",
    "                'close': 'preco_fechamento',\n",
    "                'volume': 'volume'\n",
    "            })\n",
    "            \n",
    "            # Adicionar código de negociação\n",
    "            df['cod_negociacao'] = ticker\n",
    "            \n",
    "            return df[['cod_negociacao', 'data_pregao', 'preco_fechamento', 'volume']]\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao obter dados da Brapi.dev: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def prepare_data(self, df):\n",
    "        \"\"\"\n",
    "        Prepara os dados para previsão usando o FeatureExtractor\n",
    "        \"\"\"\n",
    "        # Garantir ordenação por data\n",
    "        df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "        \n",
    "        # Extrair features\n",
    "        df_features = self.feature_extractor.transform(df)\n",
    "        \n",
    "        # Selecionar apenas as features usadas pelo modelo\n",
    "        X = df_features[self.feature_extractor.features_to_use]\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def predict(self, ticker, source='yfinance', days_back=260):\n",
    "        \"\"\"\n",
    "        Faz previsões para um determinado ticker\n",
    "        \"\"\"\n",
    "        # Definir datas\n",
    "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "        start_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Obter dados\n",
    "        if source.lower() == 'yfinance':\n",
    "            df = self.get_data_from_yfinance(ticker, start_date, end_date)\n",
    "        elif source.lower() == 'brapi':\n",
    "            df = self.get_data_from_brapi(ticker, start_date, end_date)\n",
    "        else:\n",
    "            raise ValueError(\"Fonte de dados inválida. Use 'yfinance' ou 'brapi'\")\n",
    "        \n",
    "        if df is None or df.empty:\n",
    "            print(f\"Não foi possível obter dados para {ticker}\")\n",
    "            return None\n",
    "        \n",
    "        # Preparar dados\n",
    "        X = self.prepare_data(df)\n",
    "        \n",
    "        if X is None or X.empty:\n",
    "            print(\"Não foi possível preparar os dados para previsão\")\n",
    "            return None\n",
    "        \n",
    "        # Fazer previsões\n",
    "        predictions = self.model.predict(X)\n",
    "        \n",
    "        # Criar DataFrame com resultados\n",
    "        results = df[['cod_negociacao', 'data_pregao', 'preco_fechamento']].copy()\n",
    "        results['retorno_previsto_52semanas'] = predictions\n",
    "        \n",
    "        # Adicionar data de referência para o retorno futuro\n",
    "        results['data_referencia_retorno'] = results['data_pregao'] + pd.to_timedelta(52*7, unit='days')\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def predict_multiple(self, tickers, source='yfinance', days_back=260):\n",
    "        \"\"\"\n",
    "        Faz previsões para múltiplos tickers\n",
    "        \"\"\"\n",
    "        all_results = []\n",
    "        \n",
    "        for ticker in tickers:\n",
    "            print(f\"\\nProcessando {ticker}...\")\n",
    "            result = self.predict(ticker, source, days_back)\n",
    "            \n",
    "            if result is not None:\n",
    "                all_results.append(result)\n",
    "        \n",
    "        if not all_results:\n",
    "            return None\n",
    "        \n",
    "        return pd.concat(all_results)\n",
    "\n",
    "def load_feature_extractor(file_path):\n",
    "    try:\n",
    "        # Verificar se arquivo existe\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"Arquivo {file_path} não encontrado\")\n",
    "            \n",
    "        # Carregar com tratamento de erro\n",
    "        with open(file_path, 'rb') as file:\n",
    "            return pickle.load(file)\n",
    "            \n",
    "    except AttributeError as e:\n",
    "        print(\"\\n⚠️ Erro: Classe FeatureExtractor não encontrada. Soluções possíveis:\")\n",
    "        print(\"1. Certifique-se que a classe FeatureExtractor está definida no seu script atual\")\n",
    "        print(\"2. Se você modificou a classe, recrie e salve o feature extractor novamente\")\n",
    "        print(f\"Detalhes do erro: {str(e)}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Erro ao carregar feature extractor: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_expected_annual_return(ticker, model_path='utils/modelo_xgb_treinado_2017_2018.json', \n",
    "                              feature_extractor_path='utils/feature_extractor_2017_2018.pkl'):\n",
    "    \"\"\"\n",
    "    Retorna a rentabilidade anual esperada para uma ação específica\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Código da ação (ex: 'PETR4')\n",
    "        model_path (str): Caminho para o modelo XGBoost treinado\n",
    "        feature_extractor_path (str): Caminho para o feature extractor\n",
    "        \n",
    "    Returns:\n",
    "        float: Rentabilidade anual esperada em percentual (ex: 0.15 para 15%)\n",
    "        str: Mensagem de status\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Carregar o modelo e feature extractor\n",
    "    try:\n",
    "        modelo = XGBRegressor()\n",
    "        modelo.load_model(model_path)\n",
    "        \n",
    "        with open(feature_extractor_path, 'rb') as f:\n",
    "            feature_extractor = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        return None, f\"Erro ao carregar modelo: {str(e)}\"\n",
    "    \n",
    "    # 2. Obter dados mais recentes\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker + \".SA\")\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=365)  # 1 ano de dados\n",
    "        \n",
    "        df = stock.history(start=start_date, end=end_date)\n",
    "        \n",
    "        if df.empty:\n",
    "            return None, \"Nenhum dado encontrado para o ticker\"\n",
    "            \n",
    "        # Preparar dados no formato esperado\n",
    "        df = df.reset_index().rename(columns={\n",
    "            'Date': 'data_pregao',\n",
    "            'Close': 'preco_fechamento',\n",
    "            'Volume': 'volume'\n",
    "        })\n",
    "        df['cod_negociacao'] = ticker\n",
    "    except Exception as e:\n",
    "        return None, f\"Erro ao obter dados: {str(e)}\"\n",
    "    \n",
    "    # 3. Preparar features\n",
    "    try:\n",
    "        df_features = feature_extractor.transform(df)\n",
    "        X = df_features[feature_extractor.features_to_use].iloc[[-1]]  # Pegar apenas o último dia\n",
    "    except Exception as e:\n",
    "        return None, f\"Erro ao preparar features: {str(e)}\"\n",
    "    \n",
    "    # 4. Fazer previsão\n",
    "    try:\n",
    "        pred = modelo.predict(X)\n",
    "        annual_return = pred[0]  # Retorno esperado em decimal (ex: 0.15 para 15%)\n",
    "        return annual_return, \"Previsão realizada com sucesso\"\n",
    "    except Exception as e:\n",
    "        return None, f\"Erro ao fazer previsão: {str(e)}\"\n",
    "\n",
    "\n",
    "# Exemplo de uso:\n",
    "if __name__ == \"__main__\":\n",
    "    import pickle\n",
    "    from xgboost import XGBRegressor\n",
    "    # Supondo que você já tenha o modelo e o feature extractor\n",
    "    # (substitua por como você os obtém na sua implementação)\n",
    "    \n",
    "    # Carregar o modelo e feature extractor (substitua por sua implementação real)\n",
    "    # modelo_xgb, X_data, y_data = main(\"datasets/semanal2021-2022.csv\")\n",
    "    # feature_extractor = FeatureExtractor()\n",
    "    \n",
    "    ticker = 'BBDC4'\n",
    "    \n",
    "    retorno, mensagem = get_expected_annual_return(ticker)\n",
    "    \n",
    "    if retorno is not None:\n",
    "        print(f\"\\nRentabilidade anual esperada para {ticker}: {retorno:.2%}\")\n",
    "        print(f\"Status: {mensagem}\")\n",
    "    else:\n",
    "        print(f\"\\nErro: {mensagem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0321e3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "2.3.0\n",
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)\n",
    "\n",
    "import pandas\n",
    "print(pandas.__version__)\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62b439ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cod_negociacao               data_pregao  preco_fechamento  \\\n",
      "0            PETR4 2024-11-11 00:00:00-03:00         31.811728   \n",
      "1            PETR4 2024-11-12 00:00:00-03:00         32.408470   \n",
      "2            PETR4 2024-11-13 00:00:00-03:00         32.364597   \n",
      "3            PETR4 2024-11-14 00:00:00-03:00         32.706841   \n",
      "4            PETR4 2024-11-18 00:00:00-03:00         33.522976   \n",
      "..             ...                       ...               ...   \n",
      "168          PETR4 2025-07-21 00:00:00-03:00         31.049999   \n",
      "169          PETR4 2025-07-22 00:00:00-03:00         31.350000   \n",
      "170          PETR4 2025-07-23 00:00:00-03:00         31.990000   \n",
      "171          PETR4 2025-07-24 00:00:00-03:00         31.940001   \n",
      "172          PETR4 2025-07-25 00:00:00-03:00         31.980000   \n",
      "\n",
      "     retorno_previsto_52semanas   data_referencia_retorno  \n",
      "0                      0.336298 2025-11-10 00:00:00-03:00  \n",
      "1                      0.336298 2025-11-11 00:00:00-03:00  \n",
      "2                      0.336298 2025-11-12 00:00:00-03:00  \n",
      "3                     -0.422279 2025-11-13 00:00:00-03:00  \n",
      "4                     -0.420653 2025-11-17 00:00:00-03:00  \n",
      "..                          ...                       ...  \n",
      "168                   -0.087150 2026-07-20 00:00:00-03:00  \n",
      "169                   -0.102351 2026-07-21 00:00:00-03:00  \n",
      "170                   -0.072097 2026-07-22 00:00:00-03:00  \n",
      "171                   -0.075367 2026-07-23 00:00:00-03:00  \n",
      "172                   -0.068165 2026-07-24 00:00:00-03:00  \n",
      "\n",
      "[173 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(resultados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
