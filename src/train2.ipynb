{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape final dos dados: (90838, 8)\n",
      "Valores únicos no target: count    90838.000000\n",
      "mean        -0.162388\n",
      "std          0.417102\n",
      "min         -0.958333\n",
      "25%         -0.392035\n",
      "50%         -0.172221\n",
      "75%          0.000139\n",
      "max          2.000000\n",
      "Name: target, dtype: float64\n",
      "Score R²: 0.1506\n",
      "Score R²: 0.2112\n",
      "Score R²: 0.1979\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def preparar_dados(df):\n",
    "    \"\"\"Prepara os dados iniciais com tratamento robusto do target\"\"\"\n",
    "    # Converter data\n",
    "    df['data_pregao'] = pd.to_datetime(df['data_pregao'])\n",
    "    \n",
    "    # Ordenar por ação e data\n",
    "    df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "    \n",
    "    # Calcular retorno futuro de forma segura\n",
    "    df['retorno_futuro'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "        lambda x: x.pct_change(periods=52)\n",
    "    )\n",
    "    \n",
    "    # Remover retornos extremos (outliers)\n",
    "    df['retorno_futuro'] = df['retorno_futuro'].clip(\n",
    "        lower=df['retorno_futuro'].quantile(0.01),\n",
    "        upper=df['retorno_futuro'].quantile(0.99)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extrair_features(df):\n",
    "    \"\"\"Extrai features com tratamento completo de infinitos e NA\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Garantir ordenação\n",
    "    df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "    \n",
    "    # Grupo para cálculos\n",
    "    gb = df.groupby('cod_negociacao')['preco_fechamento']\n",
    "    \n",
    "    # Função segura para retornos\n",
    "    def safe_return(current, past, min_price=0.01):\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            return np.where(\n",
    "                (past > min_price) & (current > min_price),\n",
    "                (current - past) / past,\n",
    "                np.nan\n",
    "            )\n",
    "    \n",
    "    # Médias móveis\n",
    "    for window in [4, 8, 12, 26]:\n",
    "        df[f'media_{window}w'] = gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "        df[f'vol_{window}w'] = gb.rolling(window=window).std().reset_index(level=0, drop=True)\n",
    "    \n",
    "    # Retornos protegidos\n",
    "    for weeks, periods in [(4,3), (12,11), (26,25)]:\n",
    "        preco_passado = gb.shift(periods)\n",
    "        df[f'retorno_{weeks}w'] = safe_return(df['preco_fechamento'], preco_passado)\n",
    "    \n",
    "    # Volume médio\n",
    "    vol_gb = df.groupby('cod_negociacao')['volume']\n",
    "    for window in [4, 12]:\n",
    "        df[f'volume_medio_{window}w'] = vol_gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "    \n",
    "    # Momentum com fillna\n",
    "    df['momento_4_12'] = (df['retorno_4w'].fillna(0) - df['retorno_12w'].fillna(0))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_data(X, y):\n",
    "    \"\"\"Limpeza final dos dados antes do treino\"\"\"\n",
    "    # Juntar X e y para limpeza consistente\n",
    "    data = X.copy()\n",
    "    data['target'] = y\n",
    "    \n",
    "    # Remover infinitos e NA\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # Separar novamente\n",
    "    X_clean = data.drop('target', axis=1)\n",
    "    y_clean = data['target']\n",
    "    \n",
    "    return X_clean, y_clean\n",
    "\n",
    "def treinar_modelo(df):\n",
    "    \"\"\"Função final de treino com todas as proteções\"\"\"\n",
    "    # Preparação dos dados\n",
    "    df = preparar_dados(df)\n",
    "    df = extrair_features(df)\n",
    "    \n",
    "    # Features selecionadas\n",
    "    features = ['media_4w', 'media_12w', 'vol_4w', 'vol_12w', \n",
    "                'retorno_4w', 'retorno_12w', 'volume_medio_4w',\n",
    "                'momento_4_12']\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df['retorno_futuro']\n",
    "    \n",
    "    # Limpeza final\n",
    "    X, y = clean_data(X, y)\n",
    "    \n",
    "    # Pipeline robusto\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', RandomForestRegressor(\n",
    "            n_estimators=200,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            max_depth=5  # Limite de profundidade para evitar overfitting\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Validação cruzada temporal\n",
    "    tscv = TimeSeriesSplit(n_splits=3)  # Reduzido para 3 por performance\n",
    "    \n",
    "    print(f\"Shape final dos dados: {X.shape}\")\n",
    "    print(f\"Valores únicos no target: {pd.Series(y).describe()}\")\n",
    "    \n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        score = pipeline.score(X_test, y_test)\n",
    "        print(f\"Score R²: {score:.4f}\")\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Carregar dados\n",
    "df_semanal = pd.read_csv(\"semanal2021-2022.csv\")\n",
    "\n",
    "# Treinar modelo\n",
    "modelo = treinar_modelo(df_semanal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados...\n",
      "\n",
      "Preparando target...\n",
      "\n",
      "Extraindo features...\n",
      "\n",
      "Limpando dados...\n",
      "\n",
      "Shape final dos dados: (90752, 12)\n",
      "Distribuição do target:\n",
      "count    90752.000000\n",
      "mean        -0.162085\n",
      "std          0.416844\n",
      "min         -0.958333\n",
      "25%         -0.391588\n",
      "50%         -0.172014\n",
      "75%          0.000265\n",
      "max          2.000000\n",
      "Name: retorno_futuro, dtype: float64\n",
      "\n",
      "Avaliando modelo...\n",
      "\n",
      "Resultados da Validação Cruzada:\n",
      "Fold 1: R² = 0.1395\n",
      "Fold 2: R² = 0.2309\n",
      "Fold 3: R² = 0.2150\n",
      "Média R²: 0.1951 (±0.0399)\n",
      "\n",
      "Treinando modelo final...\n",
      "Modelo não possui atributo de importância de features\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Classe para extração avançada de features sem TA-Lib\"\"\"\n",
    "    def __init__(self):\n",
    "        self.features_to_use = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Garantir ordenação correta\n",
    "        df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "        \n",
    "        # Grupo para cálculos\n",
    "        gb = df.groupby('cod_negociacao')['preco_fechamento']\n",
    "        \n",
    "        # 1. Features básicas\n",
    "        for window in [4, 8, 12, 26]:\n",
    "            df[f'media_{window}w'] = gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "            df[f'vol_{window}w'] = gb.rolling(window=window).std().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # 2. Retornos com tratamento robusto\n",
    "        def safe_return(current, past, min_price=0.01):\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                return np.where(\n",
    "                    (past > min_price) & (current > min_price),\n",
    "                    (current - past) / past,\n",
    "                    np.nan\n",
    "                )\n",
    "        \n",
    "        for weeks, periods in [(1,0), (4,3), (12,11), (26,25)]:\n",
    "            preco_passado = gb.shift(periods)\n",
    "            df[f'retorno_{weeks}w'] = safe_return(df['preco_fechamento'], preco_passado)\n",
    "        \n",
    "        # 3. Implementação simplificada de RSI sem TA-Lib\n",
    "        def calculate_rsi(series, window=14):\n",
    "            delta = series.diff()\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "            \n",
    "            avg_gain = gain.rolling(window=window).mean()\n",
    "            avg_loss = loss.rolling(window=window).mean()\n",
    "            \n",
    "            rs = avg_gain / avg_loss\n",
    "            return 100 - (100 / (1 + rs))\n",
    "        \n",
    "        df['rsi_14'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(calculate_rsi)\n",
    "        \n",
    "        # 4. Features temporais\n",
    "        for lag in [1, 2, 3, 4]:\n",
    "            df[f'retorno_lag_{lag}w'] = df.groupby('cod_negociacao')['retorno_1w'].shift(lag)\n",
    "        \n",
    "        df['ema_12'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "            lambda x: x.ewm(span=12).mean()\n",
    "        )\n",
    "        \n",
    "        # 5. Features de volume\n",
    "        vol_gb = df.groupby('cod_negociacao')['volume']\n",
    "        for window in [4, 12]:\n",
    "            df[f'volume_medio_{window}w'] = vol_gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # 6. Features setoriais/relativas (se disponível)\n",
    "        if 'setor' in df.columns:\n",
    "            df['retorno_relativo'] = df.groupby(['data_pregao', 'setor'])['retorno_4w'].transform('mean')\n",
    "            df['vol_relativa'] = df['vol_4w'] / df.groupby('data_pregao')['vol_4w'].transform('mean')\n",
    "        \n",
    "        # Definir features a serem usadas\n",
    "        self.features_to_use = [\n",
    "            'media_4w', 'media_12w', 'vol_4w', 'vol_12w',\n",
    "            'retorno_1w', 'retorno_4w', 'retorno_12w',\n",
    "            'retorno_lag_1w', 'retorno_lag_2w',\n",
    "            'volume_medio_4w', 'ema_12', 'rsi_14'\n",
    "        ]\n",
    "        \n",
    "        if 'retorno_relativo' in df.columns:\n",
    "            self.features_to_use.extend(['retorno_relativo', 'vol_relativa'])\n",
    "        \n",
    "        return df\n",
    "\n",
    "# [O resto do código permanece igual a partir da função preparar_target()...]\n",
    "\n",
    "def preparar_target(df):\n",
    "    \"\"\"Prepara o target com tratamento robusto\"\"\"\n",
    "    df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "    \n",
    "    # Calcular retorno futuro\n",
    "    df['retorno_futuro'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "        lambda x: x.pct_change(periods=52)\n",
    "    )\n",
    "    \n",
    "    # Tratar outliers extremos\n",
    "    lower = df['retorno_futuro'].quantile(0.01)\n",
    "    upper = df['retorno_futuro'].quantile(0.99)\n",
    "    df['retorno_futuro'] = df['retorno_futuro'].clip(lower, upper)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# [Continue com as outras funções: clean_data, criar_pipeline, avaliar_modelo, plot_feature_importance, main]\n",
    "def clean_data(X, y):\n",
    "    \"\"\"Limpeza final dos dados\"\"\"\n",
    "    data = X.join(y)\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.dropna()\n",
    "    return data.drop('retorno_futuro', axis=1), data['retorno_futuro']\n",
    "\n",
    "def criar_pipeline():\n",
    "    \"\"\"Cria pipeline de modelagem avançada\"\"\"\n",
    "    return Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', HistGradientBoostingRegressor(\n",
    "            max_iter=200,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=7,\n",
    "            early_stopping=True,\n",
    "            random_state=42,\n",
    "            scoring='r2'\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "def avaliar_modelo(X, y):\n",
    "    \"\"\"Avaliação robusta com validação cruzada temporal\"\"\"\n",
    "    modelo = criar_pipeline()\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        modelo, X, y,\n",
    "        cv=tscv,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nResultados da Validação Cruzada:\")\n",
    "    for i, score in enumerate(scores):\n",
    "        print(f\"Fold {i+1}: R² = {score:.4f}\")\n",
    "    print(f\"Média R²: {np.mean(scores):.4f} (±{np.std(scores):.4f})\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def plot_feature_importance(modelo, feature_names):\n",
    "    \"\"\"Visualização correta da importância das features para qualquer modelo\"\"\"\n",
    "    try:\n",
    "        # Verifica se é um pipeline ou modelo direto\n",
    "        if hasattr(modelo, 'named_steps'):\n",
    "            model = modelo.named_steps['model']\n",
    "        else:\n",
    "            model = modelo\n",
    "        \n",
    "        # Obtém as importâncias de forma genérica\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            importances = np.abs(model.coef_)\n",
    "        else:\n",
    "            print(\"Modelo não possui atributo de importância de features\")\n",
    "            return\n",
    "        \n",
    "        # Ordena as features por importância\n",
    "        indices = np.argsort(importances)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title('Importância das Features')\n",
    "        plt.barh(range(len(indices)), importances[indices], align='center')\n",
    "        plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "        plt.xlabel('Importância Relativa')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao plotar importância: {str(e)}\")\n",
    "\n",
    "def main(file_path):\n",
    "    \"\"\"Função principal para execução completa sem TA-Lib\"\"\"\n",
    "    # 1. Carregar dados\n",
    "    print(\"Carregando dados...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 2. Preparar target\n",
    "    print(\"\\nPreparando target...\")\n",
    "    df = preparar_target(df)\n",
    "    \n",
    "    # 3. Extrair features\n",
    "    print(\"\\nExtraindo features...\")\n",
    "    feature_extractor = FeatureExtractor()\n",
    "    df_features = feature_extractor.transform(df)\n",
    "    \n",
    "    # 4. Selecionar dados finais\n",
    "    X = df_features[feature_extractor.features_to_use]\n",
    "    y = df_features['retorno_futuro']\n",
    "    \n",
    "    # 5. Limpeza final\n",
    "    print(\"\\nLimpando dados...\")\n",
    "    X_clean, y_clean = clean_data(X, y)\n",
    "    \n",
    "    print(f\"\\nShape final dos dados: {X_clean.shape}\")\n",
    "    print(f\"Distribuição do target:\\n{y_clean.describe()}\")\n",
    "    \n",
    "    # 6. Avaliar modelo\n",
    "    print(\"\\nAvaliando modelo...\")\n",
    "    scores = avaliar_modelo(X_clean, y_clean)\n",
    "    \n",
    "    # 7. Treinar modelo final\n",
    "    print(\"\\nTreinando modelo final...\")\n",
    "    modelo = criar_pipeline()\n",
    "    modelo.fit(X_clean, y_clean)\n",
    "    \n",
    "    # 8. Visualizar importância das features\n",
    "    plot_feature_importance(modelo, feature_extractor.features_to_use)\n",
    "    \n",
    "    return modelo, X_clean, y_clean\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Executar pipeline completo sem TA-Lib\n",
    "    modelo_final, X_final, y_final = main(\"datasets/semanal2021-2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados...\n",
      "\n",
      "Preparando target...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Classe para extração avançada de features\"\"\"\n",
    "    def __init__(self):\n",
    "        self.features_to_use = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Garantir ordenação correta\n",
    "        if 'data_pregao' in df.columns:\n",
    "            df['data_pregao'] = pd.to_datetime(df['data_pregao'])\n",
    "            df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "        \n",
    "        # Grupo para cálculos\n",
    "        gb = df.groupby('cod_negociacao')['preco_fechamento']\n",
    "        \n",
    "        # 1. Médias móveis e volatilidade\n",
    "        for window in [4, 8, 12, 26]:\n",
    "            df[f'media_{window}w'] = gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "            df[f'vol_{window}w'] = gb.rolling(window=window).std().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # 2. Retornos protegidos contra divisão por zero\n",
    "        def safe_return(current, past, min_price=0.01):\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                return np.where(\n",
    "                    (past > min_price) & (current > min_price),\n",
    "                    (current - past) / past,\n",
    "                    np.nan\n",
    "                )\n",
    "        \n",
    "        for weeks, periods in [(1,0), (4,3), (12,11), (26,25)]:\n",
    "            preco_passado = gb.shift(periods)\n",
    "            df[f'retorno_{weeks}w'] = safe_return(df['preco_fechamento'], preco_passado)\n",
    "        \n",
    "        # 3. RSI manual (sem TA-Lib)\n",
    "        def calculate_rsi(series, window=14):\n",
    "            delta = series.diff()\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "            \n",
    "            avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
    "            avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
    "            \n",
    "            rs = avg_gain / avg_loss.replace(0, np.nan)\n",
    "            return 100 - (100 / (1 + rs.replace(np.inf, 100)))\n",
    "        \n",
    "        df['rsi_14'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(calculate_rsi)\n",
    "        \n",
    "        # 4. Features temporais\n",
    "        for lag in [1, 2, 3, 4]:\n",
    "            df[f'retorno_lag_{lag}w'] = df.groupby('cod_negociacao')['retorno_1w'].shift(lag)\n",
    "        \n",
    "        df['ema_12'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "            lambda x: x.ewm(span=12).mean()\n",
    "        )\n",
    "        \n",
    "        # 5. Features de volume\n",
    "        if 'volume' in df.columns:\n",
    "            vol_gb = df.groupby('cod_negociacao')['volume']\n",
    "            for window in [4, 12]:\n",
    "                df[f'volume_medio_{window}w'] = vol_gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # Definir features a serem usadas\n",
    "        self.features_to_use = [\n",
    "            'media_4w', 'media_12w', 'vol_4w', 'vol_12w',\n",
    "            # 'retorno_1w',\n",
    "            'retorno_4w', 'retorno_12w',\n",
    "            # 'retorno_lag_1w', 'retorno_lag_2w',\n",
    "            'volume_medio_4w', 'ema_12', 'rsi_14'\n",
    "        ]\n",
    "        \n",
    "        return df\n",
    "\n",
    "def preparar_target(df):\n",
    "    \"\"\"Prepara o target com tratamento robusto\"\"\"\n",
    "    df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "    \n",
    "    # Calcular retorno futuro de 52 semanas\n",
    "    df['retorno_futuro'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "        lambda x: x.pct_change(periods=52)\n",
    "    )\n",
    "    \n",
    "    # Remover outliers extremos\n",
    "    if 'retorno_futuro' in df.columns:\n",
    "        lower = df['retorno_futuro'].quantile(0.01)\n",
    "        upper = df['retorno_futuro'].quantile(0.99)\n",
    "        df['retorno_futuro'] = df['retorno_futuro'].clip(lower, upper)\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_data(X, y):\n",
    "    \"\"\"Limpeza final dos dados\"\"\"\n",
    "    data = X.join(y)\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.dropna()\n",
    "    return data.drop('retorno_futuro', axis=1), data['retorno_futuro']\n",
    "\n",
    "def criar_pipeline_xgb():\n",
    "    \"\"\"Pipeline com XGBoost otimizado\"\"\"\n",
    "    return Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', XGBRegressor(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            eval_metric='rmse'\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "def treinar_avaliar_xgb(X, y):\n",
    "    \"\"\"Treinamento e avaliação personalizada com validação temporal\"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    scores = []\n",
    "    modelos = []\n",
    "    \n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Criar e treinar modelo\n",
    "        xgb = XGBRegressor(\n",
    "            n_estimators=500,  # Número maior pois usamos early stopping\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            early_stopping_rounds=20,\n",
    "            eval_metric='rmse'\n",
    "        )\n",
    "        \n",
    "        # Treinar com early stopping\n",
    "        xgb.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Avaliar\n",
    "        y_pred = xgb.predict(X_val)\n",
    "        score = r2_score(y_val, y_pred)\n",
    "        scores.append(score)\n",
    "        modelos.append(xgb)\n",
    "        \n",
    "        print(f\"Fold {len(scores)}: R² = {score:.4f} | Melhor iteração: {xgb.best_iteration}\")\n",
    "    \n",
    "    print(f\"\\nR² Médio: {np.mean(scores):.4f} (±{np.std(scores):.4f})\")\n",
    "    return modelos, scores\n",
    "\n",
    "def plot_xgb_importance(modelo, feature_names):\n",
    "    \"\"\"Visualização da importância das features no XGBoost\"\"\"\n",
    "    importances = modelo.feature_importances_\n",
    "    \n",
    "    # Cria DataFrame para melhor visualização\n",
    "    feat_imp = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance')\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(feat_imp)), feat_imp['Importance'], align='center')\n",
    "    plt.yticks(range(len(feat_imp)), feat_imp['Feature'])\n",
    "    plt.title('Importância das Features - XGBoost')\n",
    "    plt.xlabel('Importância Relativa')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main(file_path):\n",
    "    \"\"\"Função principal\"\"\"\n",
    "    try:\n",
    "        # 1. Carregar dados\n",
    "        print(\"Carregando dados...\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # 2. Preparar target\n",
    "        print(\"\\nPreparando target...\")\n",
    "        df = preparar_target(df)\n",
    "        \n",
    "        # 3. Extrair features\n",
    "        print(\"\\nExtraindo features...\")\n",
    "        feature_extractor = FeatureExtractor()\n",
    "        df_features = feature_extractor.transform(df)\n",
    "        \n",
    "        # 4. Selecionar dados finais\n",
    "        X = df_features[feature_extractor.features_to_use]\n",
    "        y = df_features['retorno_futuro']\n",
    "        \n",
    "        # 5. Limpeza final\n",
    "        print(\"\\nLimpando dados...\")\n",
    "        X_clean, y_clean = clean_data(X, y)\n",
    "        \n",
    "        print(f\"\\nDados finais: {X_clean.shape[0]} observações\")\n",
    "        print(f\"Features: {X_clean.shape[1]} variáveis\")\n",
    "        \n",
    "        # 6. Treinar e avaliar\n",
    "        print(\"\\nTreinando XGBoost com validação temporal...\")\n",
    "        modelos, scores = treinar_avaliar_xgb(X_clean, y_clean)\n",
    "        \n",
    "        # 7. Treinar modelo final com todos os dados\n",
    "        print(\"\\nTreinando modelo final...\")\n",
    "        modelo_final = XGBRegressor(\n",
    "            n_estimators=int(np.mean([m.best_iteration for m in modelos])) + 20,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        modelo_final.fit(X_clean, y_clean)\n",
    "        \n",
    "        # 8. Visualizar importância\n",
    "        plot_xgb_importance(modelo_final, feature_extractor.features_to_use)\n",
    "\n",
    "        # 9. Salvar o modelo treinado\n",
    "        print(\"\\nSalvando modelo treinado...\")\n",
    "        modelo_final.save_model('modelo_xgb_treinado.json')\n",
    "        \n",
    "        # Salvar também o feature extractor\n",
    "        print(feature_extractor)\n",
    "        print(df_features)\n",
    "        with open('feature_extractor.pkl', 'wb') as file:\n",
    "            pickle.dump(feature_extractor, file)\n",
    "        \n",
    "        print(\"Modelo e feature extractor salvos com sucesso!\")\n",
    "        \n",
    "        return modelo_final, X_clean, y_clean\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nErro: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Executar pipeline\n",
    "    modelo_xgb, X_data, y_data = main(\"datasets/semanal2021-2022.csv\")\n",
    "    \n",
    "    if modelo_xgb is not None:\n",
    "        print(\"\\nModelo XGBoost treinado com sucesso!\")\n",
    "        # Exemplo de previsão\n",
    "        sample_pred = modelo_xgb.predict(X_data.head(1))\n",
    "        print(f\"Exemplo de previsão para a primeira amostra: {sample_pred[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados...\n",
      "\n",
      "Preparando target...\n",
      "\n",
      "Extraindo features...\n",
      "\n",
      "Limpando dados...\n",
      "\n",
      "Dados finais: 47999 observações\n",
      "Features: 9 variáveis\n",
      "\n",
      "Treinando XGBoost com validação temporal...\n",
      "Fold 1: R² = 0.1279 | Melhor iteração: 21\n",
      "Fold 2: R² = 0.2911 | Melhor iteração: 69\n",
      "Fold 3: R² = 0.2419 | Melhor iteração: 88\n",
      "\n",
      "R² Médio: 0.2203 (±0.0683)\n",
      "\n",
      "Treinando modelo final...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salvando modelo treinado...\n",
      "FeatureExtractor()\n",
      "       cod_negociacao   ano  semana data_pregao  preco_abertura  preco_maximo  \\\n",
      "0              AALL34  2017      10  2017-03-06          140.91        141.31   \n",
      "1              AALL34  2017      11  2017-03-13          134.07        134.07   \n",
      "2              AALL34  2017      12  2017-03-20          128.05        128.05   \n",
      "3              AALL34  2017      15  2017-04-10          134.02        134.02   \n",
      "4              AALL34  2017      16  2017-04-17          135.79        135.79   \n",
      "...               ...   ...     ...         ...             ...           ...   \n",
      "391119         XTED11  2018      48  2018-11-26           17.85         17.86   \n",
      "391120         XTED11  2018      49  2018-12-03           17.98         18.00   \n",
      "391121         XTED11  2018      50  2018-12-10           17.03         17.50   \n",
      "391122         XTED11  2018      51  2018-12-17           16.80         17.99   \n",
      "391123         XTED11  2018      52  2018-12-26           17.97         18.00   \n",
      "\n",
      "        preco_minimo  preco_fechamento  preco_medio   volume  ...  \\\n",
      "0             139.79            139.79      140.545  2712808  ...   \n",
      "1             134.07            134.07      134.070  1756317  ...   \n",
      "2             128.05            128.05      128.050    51220  ...   \n",
      "3             134.02            134.02      134.020   241236  ...   \n",
      "4             135.79            135.79      135.790    27158  ...   \n",
      "...              ...               ...          ...      ...  ...   \n",
      "391119         17.40             17.68       17.592    73098  ...   \n",
      "391120         16.90             17.80       17.328    52311  ...   \n",
      "391121         16.80             16.80       17.130    70538  ...   \n",
      "391122         16.75             17.75       17.312    77169  ...   \n",
      "391123         17.41             17.90       17.690    10303  ...   \n",
      "\n",
      "        retorno_12w retorno_26w     rsi_14 retorno_lag_1w retorno_lag_2w  \\\n",
      "0               NaN         NaN        NaN            NaN            NaN   \n",
      "1               NaN         NaN   0.000000            0.0            NaN   \n",
      "2               NaN         NaN   0.000000            0.0            0.0   \n",
      "3               NaN         NaN  33.709768            0.0            0.0   \n",
      "4               NaN         NaN  39.733060            0.0            0.0   \n",
      "...             ...         ...        ...            ...            ...   \n",
      "391119     0.060588   -0.018323  55.357143            0.0            0.0   \n",
      "391120     0.023577   -0.029973  48.494453            0.0            0.0   \n",
      "391121     0.023143   -0.080460  45.671642            0.0            0.0   \n",
      "391122     0.080999   -0.024725  57.780980            0.0            0.0   \n",
      "391123     0.082225   -0.005556  54.003140            0.0            0.0   \n",
      "\n",
      "        retorno_lag_3w  retorno_lag_4w      ema_12  volume_medio_4w  \\\n",
      "0                  NaN             NaN  139.790000              NaN   \n",
      "1                  NaN             NaN  136.691667              NaN   \n",
      "2                  NaN             NaN  133.318822              NaN   \n",
      "3                  0.0             NaN  133.540157       1190395.25   \n",
      "4                  0.0             0.0  134.151431        518982.75   \n",
      "...                ...             ...         ...              ...   \n",
      "391119             0.0             0.0   17.393081         88982.50   \n",
      "391120             0.0             0.0   17.455684         62990.25   \n",
      "391121             0.0             0.0   17.354809         55460.25   \n",
      "391122             0.0             0.0   17.415608         68279.00   \n",
      "391123             0.0             0.0   17.490130         52580.25   \n",
      "\n",
      "        volume_medio_12w  \n",
      "0                    NaN  \n",
      "1                    NaN  \n",
      "2                    NaN  \n",
      "3                    NaN  \n",
      "4                    NaN  \n",
      "...                  ...  \n",
      "391119     103993.083333  \n",
      "391120      93635.666667  \n",
      "391121      86934.166667  \n",
      "391122      87525.333333  \n",
      "391123      85936.416667  \n",
      "\n",
      "[391124 rows x 36 columns]\n",
      "Modelo e feature extractor salvos com sucesso!\n",
      "\n",
      "Modelo XGBoost treinado com sucesso!\n",
      "Exemplo de previsão para a primeira amostra: -0.0830\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import r2_score\n",
    "import pickle\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Classe para extração avançada de features\"\"\"\n",
    "    def __init__(self):\n",
    "        self.features_to_use = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Garantir ordenação correta\n",
    "        if 'data_pregao' in df.columns:\n",
    "            df['data_pregao'] = pd.to_datetime(df['data_pregao'])\n",
    "            df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "        \n",
    "        # Grupo para cálculos\n",
    "        gb = df.groupby('cod_negociacao')['preco_fechamento']\n",
    "        \n",
    "        # 1. Médias móveis e volatilidade\n",
    "        for window in [4, 8, 12, 26]:\n",
    "            df[f'media_{window}w'] = gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "            df[f'vol_{window}w'] = gb.rolling(window=window).std().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # 2. Retornos protegidos contra divisão por zero\n",
    "        def safe_return(current, past, min_price=0.01):\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                return np.where(\n",
    "                    (past > min_price) & (current > min_price),\n",
    "                    (current - past) / past,\n",
    "                    np.nan\n",
    "                )\n",
    "        \n",
    "        for weeks, periods in [(1,0), (4,3), (12,11), (26,25)]:\n",
    "            preco_passado = gb.shift(periods)\n",
    "            df[f'retorno_{weeks}w'] = safe_return(df['preco_fechamento'], preco_passado)\n",
    "        \n",
    "        # 3. RSI manual (sem TA-Lib)\n",
    "        def calculate_rsi(series, window=14):\n",
    "            delta = series.diff()\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "            \n",
    "            avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
    "            avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
    "            \n",
    "            rs = avg_gain / avg_loss.replace(0, np.nan)\n",
    "            return 100 - (100 / (1 + rs.replace(np.inf, 100)))\n",
    "        \n",
    "        df['rsi_14'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(calculate_rsi)\n",
    "        \n",
    "        # 4. Features temporais\n",
    "        for lag in [1, 2, 3, 4]:\n",
    "            df[f'retorno_lag_{lag}w'] = df.groupby('cod_negociacao')['retorno_1w'].shift(lag)\n",
    "        \n",
    "        df['ema_12'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "            lambda x: x.ewm(span=12).mean()\n",
    "        )\n",
    "        \n",
    "        # 5. Features de volume\n",
    "        if 'volume' in df.columns:\n",
    "            vol_gb = df.groupby('cod_negociacao')['volume']\n",
    "            for window in [4, 12]:\n",
    "                df[f'volume_medio_{window}w'] = vol_gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # Definir features a serem usadas\n",
    "        self.features_to_use = [\n",
    "            'media_4w', 'media_12w', 'vol_4w', 'vol_12w',\n",
    "            # 'retorno_1w',\n",
    "            'retorno_4w', 'retorno_12w',\n",
    "            # 'retorno_lag_1w', 'retorno_lag_2w',\n",
    "            'volume_medio_4w', 'ema_12', 'rsi_14'\n",
    "        ]\n",
    "        \n",
    "        return df\n",
    "\n",
    "def preparar_target(df):\n",
    "    \"\"\"Prepara o target com tratamento robusto\"\"\"\n",
    "    df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "    \n",
    "    # Calcular retorno futuro de 52 semanas\n",
    "    df['retorno_futuro'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "        lambda x: x.pct_change(periods=52)\n",
    "    )\n",
    "    \n",
    "    # Remover outliers extremos\n",
    "    if 'retorno_futuro' in df.columns:\n",
    "        lower = df['retorno_futuro'].quantile(0.01)\n",
    "        upper = df['retorno_futuro'].quantile(0.99)\n",
    "        df['retorno_futuro'] = df['retorno_futuro'].clip(lower, upper)\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_data(X, y):\n",
    "    \"\"\"Limpeza final dos dados\"\"\"\n",
    "    data = X.join(y)\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.dropna()\n",
    "    return data.drop('retorno_futuro', axis=1), data['retorno_futuro']\n",
    "\n",
    "def criar_pipeline_xgb():\n",
    "    \"\"\"Pipeline com XGBoost otimizado\"\"\"\n",
    "    return Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', XGBRegressor(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            eval_metric='rmse'\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "def treinar_avaliar_xgb(X, y):\n",
    "    \"\"\"Treinamento e avaliação personalizada com validação temporal\"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    scores = []\n",
    "    modelos = []\n",
    "    \n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Criar e treinar modelo\n",
    "        xgb = XGBRegressor(\n",
    "            n_estimators=500,  # Número maior pois usamos early stopping\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            early_stopping_rounds=20,\n",
    "            eval_metric='rmse'\n",
    "        )\n",
    "        \n",
    "        # Treinar com early stopping\n",
    "        xgb.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Avaliar\n",
    "        y_pred = xgb.predict(X_val)\n",
    "        score = r2_score(y_val, y_pred)\n",
    "        scores.append(score)\n",
    "        modelos.append(xgb)\n",
    "        \n",
    "        print(f\"Fold {len(scores)}: R² = {score:.4f} | Melhor iteração: {xgb.best_iteration}\")\n",
    "    \n",
    "    print(f\"\\nR² Médio: {np.mean(scores):.4f} (±{np.std(scores):.4f})\")\n",
    "    return modelos, scores\n",
    "\n",
    "def plot_xgb_importance(modelo, feature_names):\n",
    "    \"\"\"Visualização da importância das features no XGBoost\"\"\"\n",
    "    importances = modelo.feature_importances_\n",
    "    \n",
    "    # Cria DataFrame para melhor visualização\n",
    "    feat_imp = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance')\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(feat_imp)), feat_imp['Importance'], align='center')\n",
    "    plt.yticks(range(len(feat_imp)), feat_imp['Feature'])\n",
    "    plt.title('Importância das Features - XGBoost')\n",
    "    plt.xlabel('Importância Relativa')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main(file_path):\n",
    "    \"\"\"Função principal\"\"\"\n",
    "    try:\n",
    "        # 1. Carregar dados\n",
    "        print(\"Carregando dados...\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # 2. Preparar target\n",
    "        print(\"\\nPreparando target...\")\n",
    "        df = preparar_target(df)\n",
    "        \n",
    "        # 3. Extrair features\n",
    "        print(\"\\nExtraindo features...\")\n",
    "        feature_extractor = FeatureExtractor()\n",
    "        df_features = feature_extractor.transform(df)\n",
    "        \n",
    "        # 4. Selecionar dados finais\n",
    "        X = df_features[feature_extractor.features_to_use]\n",
    "        y = df_features['retorno_futuro']\n",
    "        \n",
    "        # 5. Limpeza final\n",
    "        print(\"\\nLimpando dados...\")\n",
    "        X_clean, y_clean = clean_data(X, y)\n",
    "        \n",
    "        print(f\"\\nDados finais: {X_clean.shape[0]} observações\")\n",
    "        print(f\"Features: {X_clean.shape[1]} variáveis\")\n",
    "        \n",
    "        # 6. Treinar e avaliar\n",
    "        print(\"\\nTreinando XGBoost com validação temporal...\")\n",
    "        modelos, scores = treinar_avaliar_xgb(X_clean, y_clean)\n",
    "        \n",
    "        # 7. Treinar modelo final com todos os dados\n",
    "        print(\"\\nTreinando modelo final...\")\n",
    "        modelo_final = XGBRegressor(\n",
    "            n_estimators=int(np.mean([m.best_iteration for m in modelos])) + 20,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        modelo_final.fit(X_clean, y_clean)\n",
    "        \n",
    "        # 8. Visualizar importância\n",
    "        plot_xgb_importance(modelo_final, feature_extractor.features_to_use)\n",
    "\n",
    "        # 9. Salvar o modelo treinado\n",
    "        print(\"\\nSalvando modelo treinado...\")\n",
    "        modelo_final.save_model('modelo_xgb_treinado.json')\n",
    "        \n",
    "        # Salvar também o feature extractor\n",
    "        print(feature_extractor)\n",
    "        print(df_features)\n",
    "        with open('feature_extractor.pkl', 'wb') as file:\n",
    "            pickle.dump(feature_extractor, file)\n",
    "        \n",
    "        print(\"Modelo e feature extractor salvos com sucesso!\")\n",
    "        \n",
    "        return modelo_final, X_clean, y_clean\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nErro: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Executar pipeline\n",
    "    modelo_xgb, X_data, y_data = main(\"datasets/acoes_semanais2017_2018.csv\")\n",
    "    \n",
    "    if modelo_xgb is not None:\n",
    "        print(\"\\nModelo XGBoost treinado com sucesso!\")\n",
    "        # Exemplo de previsão\n",
    "        sample_pred = modelo_xgb.predict(X_data.head(1))\n",
    "        print(f\"Exemplo de previsão para a primeira amostra: {sample_pred[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    91321.000000\n",
       "mean        -0.166043\n",
       "std          0.419488\n",
       "min         -0.958333\n",
       "25%         -0.396154\n",
       "50%         -0.173913\n",
       "75%          0.000000\n",
       "max          2.000000\n",
       "Name: retorno_futuro, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_xgb.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
