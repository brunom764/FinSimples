{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m df_semanal \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msemanal2021-2022.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Treinar modelo\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m modelo \u001b[38;5;241m=\u001b[39m \u001b[43mtreinar_modelo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_semanal\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 100\u001b[0m, in \u001b[0;36mtreinar_modelo\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     97\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[train_index], X\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[0;32m     98\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[1;32m--> 100\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m score \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore R²: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Colaborador\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Colaborador\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:663\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    658\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    659\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    660\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    661\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    662\u001b[0m         )\n\u001b[1;32m--> 663\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Colaborador\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Colaborador\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:359\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 359\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[0;32m    372\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[1;32mc:\\Users\\Colaborador\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2971\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2969\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2970\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2971\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2972\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Colaborador\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1385\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1366\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[0;32m   1368\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1369\u001b[0m     X,\n\u001b[0;32m   1370\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1383\u001b[0m )\n\u001b[1;32m-> 1385\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\Colaborador\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1395\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1395\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1405\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32mc:\\Users\\Colaborador\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1102\u001b[0m     )\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m-> 1105\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1114\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Colaborador\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Colaborador\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def preparar_dados(df):\n",
    "    \"\"\"Prepara os dados iniciais\"\"\"\n",
    "    # Converter data\n",
    "    df['data_pregao'] = pd.to_datetime(df['data_pregao'])\n",
    "    \n",
    "    # Ordenar por ação e data\n",
    "    df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "    \n",
    "    # Calcular retorno futuro (52 semanas)\n",
    "    df['retorno_futuro'] = df.groupby('cod_negociacao')['preco_fechamento'].pct_change(periods=52)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extrair_features(df):\n",
    "    \"\"\"Extrai features de forma vetorizada com tratamento de divisão por zero\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Agrupa por ação para cálculos de janela\n",
    "    gb = df.groupby('cod_negociacao')['preco_fechamento']\n",
    "    \n",
    "    # Médias móveis e volatilidade\n",
    "    for window in [4, 8, 12, 26]:\n",
    "        df[f'media_{window}w'] = gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "        df[f'vol_{window}w'] = gb.rolling(window=window).std().reset_index(level=0, drop=True)\n",
    "    \n",
    "    # Retornos em diferentes janelas - com tratamento para preço zero\n",
    "    for weeks, periods in [(4,3), (12,11), (26,25)]:\n",
    "        preco_passado = gb.shift(periods)\n",
    "        # Calcula retorno com tratamento para divisão por zero\n",
    "        retorno = np.where(\n",
    "            (preco_passado > 0.001),  # Considera apenas se preço passado > 0.001\n",
    "            (df['preco_fechamento'] / preco_passado) - 1,\n",
    "            np.nan  # Retorna NA se preço passado for zero ou muito pequeno\n",
    "        )\n",
    "        df[f'retorno_{weeks}w'] = retorno\n",
    "    \n",
    "    # Features de volume\n",
    "    vol_gb = df.groupby('cod_negociacao')['volume']\n",
    "    for window in [4, 12]:\n",
    "        df[f'volume_medio_{window}w'] = vol_gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "    \n",
    "    # Momentum\n",
    "    df['momento_4_12'] = df['retorno_4w'] - df['retorno_12w']\n",
    "    \n",
    "    df.shape\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocessamento_pipeline():\n",
    "    \"\"\"Cria pipeline de pré-processamento\"\"\"\n",
    "    return Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "def treinar_modelo(df):\n",
    "    \"\"\"Treina o modelo com validação temporal\"\"\"\n",
    "    # Preparar dados\n",
    "    df = preparar_dados(df)\n",
    "    df = extrair_features(df)\n",
    "    \n",
    "    # Remover NA gerados pelas janelas e retorno futuro\n",
    "    df = df.dropna(subset=['retorno_futuro'])\n",
    "    \n",
    "    # Separar features e target\n",
    "    features = ['media_4w', 'media_12w', 'vol_4w', 'vol_12w', \n",
    "                'retorno_4w', 'retorno_12w', 'volume_medio_4w',\n",
    "                'momento_4_12']\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df['retorno_futuro']\n",
    "    \n",
    "    # Tratar infinitos e NA\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    y = y.loc[X.index]\n",
    "    \n",
    "    # Pipeline de modelagem\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessamento_pipeline()),\n",
    "        ('model', RandomForestRegressor(n_estimators=200, \n",
    "                                      random_state=42,\n",
    "                                      n_jobs=-1))\n",
    "    ])\n",
    "    \n",
    "    # Validação cruzada temporal\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        score = pipeline.score(X_test, y_test)\n",
    "        print(f\"Score R²: {score:.4f}\")\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Carregar dados\n",
    "df_semanal = pd.read_csv(\"semanal2021-2022.csv\")\n",
    "\n",
    "# Treinar modelo\n",
    "modelo = treinar_modelo(df_semanal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape final dos dados: (90838, 8)\n",
      "Valores únicos no target: count    90838.000000\n",
      "mean        -0.162388\n",
      "std          0.417102\n",
      "min         -0.958333\n",
      "25%         -0.392035\n",
      "50%         -0.172221\n",
      "75%          0.000139\n",
      "max          2.000000\n",
      "Name: target, dtype: float64\n",
      "Score R²: 0.1506\n",
      "Score R²: 0.2112\n",
      "Score R²: 0.1979\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def preparar_dados(df):\n",
    "    \"\"\"Prepara os dados iniciais com tratamento robusto do target\"\"\"\n",
    "    # Converter data\n",
    "    df['data_pregao'] = pd.to_datetime(df['data_pregao'])\n",
    "    \n",
    "    # Ordenar por ação e data\n",
    "    df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "    \n",
    "    # Calcular retorno futuro de forma segura\n",
    "    df['retorno_futuro'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "        lambda x: x.pct_change(periods=52)\n",
    "    )\n",
    "    \n",
    "    # Remover retornos extremos (outliers)\n",
    "    df['retorno_futuro'] = df['retorno_futuro'].clip(\n",
    "        lower=df['retorno_futuro'].quantile(0.01),\n",
    "        upper=df['retorno_futuro'].quantile(0.99)\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extrair_features(df):\n",
    "    \"\"\"Extrai features com tratamento completo de infinitos e NA\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Garantir ordenação\n",
    "    df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "    \n",
    "    # Grupo para cálculos\n",
    "    gb = df.groupby('cod_negociacao')['preco_fechamento']\n",
    "    \n",
    "    # Função segura para retornos\n",
    "    def safe_return(current, past, min_price=0.01):\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            return np.where(\n",
    "                (past > min_price) & (current > min_price),\n",
    "                (current - past) / past,\n",
    "                np.nan\n",
    "            )\n",
    "    \n",
    "    # Médias móveis\n",
    "    for window in [4, 8, 12, 26]:\n",
    "        df[f'media_{window}w'] = gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "        df[f'vol_{window}w'] = gb.rolling(window=window).std().reset_index(level=0, drop=True)\n",
    "    \n",
    "    # Retornos protegidos\n",
    "    for weeks, periods in [(4,3), (12,11), (26,25)]:\n",
    "        preco_passado = gb.shift(periods)\n",
    "        df[f'retorno_{weeks}w'] = safe_return(df['preco_fechamento'], preco_passado)\n",
    "    \n",
    "    # Volume médio\n",
    "    vol_gb = df.groupby('cod_negociacao')['volume']\n",
    "    for window in [4, 12]:\n",
    "        df[f'volume_medio_{window}w'] = vol_gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "    \n",
    "    # Momentum com fillna\n",
    "    df['momento_4_12'] = (df['retorno_4w'].fillna(0) - df['retorno_12w'].fillna(0))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_data(X, y):\n",
    "    \"\"\"Limpeza final dos dados antes do treino\"\"\"\n",
    "    # Juntar X e y para limpeza consistente\n",
    "    data = X.copy()\n",
    "    data['target'] = y\n",
    "    \n",
    "    # Remover infinitos e NA\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # Separar novamente\n",
    "    X_clean = data.drop('target', axis=1)\n",
    "    y_clean = data['target']\n",
    "    \n",
    "    return X_clean, y_clean\n",
    "\n",
    "def treinar_modelo(df):\n",
    "    \"\"\"Função final de treino com todas as proteções\"\"\"\n",
    "    # Preparação dos dados\n",
    "    df = preparar_dados(df)\n",
    "    df = extrair_features(df)\n",
    "    \n",
    "    # Features selecionadas\n",
    "    features = ['media_4w', 'media_12w', 'vol_4w', 'vol_12w', \n",
    "                'retorno_4w', 'retorno_12w', 'volume_medio_4w',\n",
    "                'momento_4_12']\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df['retorno_futuro']\n",
    "    \n",
    "    # Limpeza final\n",
    "    X, y = clean_data(X, y)\n",
    "    \n",
    "    # Pipeline robusto\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', RandomForestRegressor(\n",
    "            n_estimators=200,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            max_depth=5  # Limite de profundidade para evitar overfitting\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Validação cruzada temporal\n",
    "    tscv = TimeSeriesSplit(n_splits=3)  # Reduzido para 3 por performance\n",
    "    \n",
    "    print(f\"Shape final dos dados: {X.shape}\")\n",
    "    print(f\"Valores únicos no target: {pd.Series(y).describe()}\")\n",
    "    \n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        score = pipeline.score(X_test, y_test)\n",
    "        print(f\"Score R²: {score:.4f}\")\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Carregar dados\n",
    "df_semanal = pd.read_csv(\"semanal2021-2022.csv\")\n",
    "\n",
    "# Treinar modelo\n",
    "modelo = treinar_modelo(df_semanal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados...\n",
      "\n",
      "Preparando target...\n",
      "\n",
      "Extraindo features...\n",
      "\n",
      "Limpando dados...\n",
      "\n",
      "Shape final dos dados: (90752, 12)\n",
      "Distribuição do target:\n",
      "count    90752.000000\n",
      "mean        -0.162085\n",
      "std          0.416844\n",
      "min         -0.958333\n",
      "25%         -0.391588\n",
      "50%         -0.172014\n",
      "75%          0.000265\n",
      "max          2.000000\n",
      "Name: retorno_futuro, dtype: float64\n",
      "\n",
      "Avaliando modelo...\n",
      "\n",
      "Resultados da Validação Cruzada:\n",
      "Fold 1: R² = 0.1395\n",
      "Fold 2: R² = 0.2309\n",
      "Fold 3: R² = 0.2150\n",
      "Média R²: 0.1951 (±0.0399)\n",
      "\n",
      "Treinando modelo final...\n",
      "Modelo não possui atributo de importância de features\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Classe para extração avançada de features sem TA-Lib\"\"\"\n",
    "    def __init__(self):\n",
    "        self.features_to_use = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Garantir ordenação correta\n",
    "        df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "        \n",
    "        # Grupo para cálculos\n",
    "        gb = df.groupby('cod_negociacao')['preco_fechamento']\n",
    "        \n",
    "        # 1. Features básicas\n",
    "        for window in [4, 8, 12, 26]:\n",
    "            df[f'media_{window}w'] = gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "            df[f'vol_{window}w'] = gb.rolling(window=window).std().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # 2. Retornos com tratamento robusto\n",
    "        def safe_return(current, past, min_price=0.01):\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                return np.where(\n",
    "                    (past > min_price) & (current > min_price),\n",
    "                    (current - past) / past,\n",
    "                    np.nan\n",
    "                )\n",
    "        \n",
    "        for weeks, periods in [(1,0), (4,3), (12,11), (26,25)]:\n",
    "            preco_passado = gb.shift(periods)\n",
    "            df[f'retorno_{weeks}w'] = safe_return(df['preco_fechamento'], preco_passado)\n",
    "        \n",
    "        # 3. Implementação simplificada de RSI sem TA-Lib\n",
    "        def calculate_rsi(series, window=14):\n",
    "            delta = series.diff()\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "            \n",
    "            avg_gain = gain.rolling(window=window).mean()\n",
    "            avg_loss = loss.rolling(window=window).mean()\n",
    "            \n",
    "            rs = avg_gain / avg_loss\n",
    "            return 100 - (100 / (1 + rs))\n",
    "        \n",
    "        df['rsi_14'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(calculate_rsi)\n",
    "        \n",
    "        # 4. Features temporais\n",
    "        for lag in [1, 2, 3, 4]:\n",
    "            df[f'retorno_lag_{lag}w'] = df.groupby('cod_negociacao')['retorno_1w'].shift(lag)\n",
    "        \n",
    "        df['ema_12'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "            lambda x: x.ewm(span=12).mean()\n",
    "        )\n",
    "        \n",
    "        # 5. Features de volume\n",
    "        vol_gb = df.groupby('cod_negociacao')['volume']\n",
    "        for window in [4, 12]:\n",
    "            df[f'volume_medio_{window}w'] = vol_gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # 6. Features setoriais/relativas (se disponível)\n",
    "        if 'setor' in df.columns:\n",
    "            df['retorno_relativo'] = df.groupby(['data_pregao', 'setor'])['retorno_4w'].transform('mean')\n",
    "            df['vol_relativa'] = df['vol_4w'] / df.groupby('data_pregao')['vol_4w'].transform('mean')\n",
    "        \n",
    "        # Definir features a serem usadas\n",
    "        self.features_to_use = [\n",
    "            'media_4w', 'media_12w', 'vol_4w', 'vol_12w',\n",
    "            'retorno_1w', 'retorno_4w', 'retorno_12w',\n",
    "            'retorno_lag_1w', 'retorno_lag_2w',\n",
    "            'volume_medio_4w', 'ema_12', 'rsi_14'\n",
    "        ]\n",
    "        \n",
    "        if 'retorno_relativo' in df.columns:\n",
    "            self.features_to_use.extend(['retorno_relativo', 'vol_relativa'])\n",
    "        \n",
    "        return df\n",
    "\n",
    "# [O resto do código permanece igual a partir da função preparar_target()...]\n",
    "\n",
    "def preparar_target(df):\n",
    "    \"\"\"Prepara o target com tratamento robusto\"\"\"\n",
    "    df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "    \n",
    "    # Calcular retorno futuro\n",
    "    df['retorno_futuro'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "        lambda x: x.pct_change(periods=52)\n",
    "    )\n",
    "    \n",
    "    # Tratar outliers extremos\n",
    "    lower = df['retorno_futuro'].quantile(0.01)\n",
    "    upper = df['retorno_futuro'].quantile(0.99)\n",
    "    df['retorno_futuro'] = df['retorno_futuro'].clip(lower, upper)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# [Continue com as outras funções: clean_data, criar_pipeline, avaliar_modelo, plot_feature_importance, main]\n",
    "def clean_data(X, y):\n",
    "    \"\"\"Limpeza final dos dados\"\"\"\n",
    "    data = X.join(y)\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.dropna()\n",
    "    return data.drop('retorno_futuro', axis=1), data['retorno_futuro']\n",
    "\n",
    "def criar_pipeline():\n",
    "    \"\"\"Cria pipeline de modelagem avançada\"\"\"\n",
    "    return Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', HistGradientBoostingRegressor(\n",
    "            max_iter=200,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=7,\n",
    "            early_stopping=True,\n",
    "            random_state=42,\n",
    "            scoring='r2'\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "def avaliar_modelo(X, y):\n",
    "    \"\"\"Avaliação robusta com validação cruzada temporal\"\"\"\n",
    "    modelo = criar_pipeline()\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        modelo, X, y,\n",
    "        cv=tscv,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nResultados da Validação Cruzada:\")\n",
    "    for i, score in enumerate(scores):\n",
    "        print(f\"Fold {i+1}: R² = {score:.4f}\")\n",
    "    print(f\"Média R²: {np.mean(scores):.4f} (±{np.std(scores):.4f})\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def plot_feature_importance(modelo, feature_names):\n",
    "    \"\"\"Visualização correta da importância das features para qualquer modelo\"\"\"\n",
    "    try:\n",
    "        # Verifica se é um pipeline ou modelo direto\n",
    "        if hasattr(modelo, 'named_steps'):\n",
    "            model = modelo.named_steps['model']\n",
    "        else:\n",
    "            model = modelo\n",
    "        \n",
    "        # Obtém as importâncias de forma genérica\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            importances = np.abs(model.coef_)\n",
    "        else:\n",
    "            print(\"Modelo não possui atributo de importância de features\")\n",
    "            return\n",
    "        \n",
    "        # Ordena as features por importância\n",
    "        indices = np.argsort(importances)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title('Importância das Features')\n",
    "        plt.barh(range(len(indices)), importances[indices], align='center')\n",
    "        plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "        plt.xlabel('Importância Relativa')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao plotar importância: {str(e)}\")\n",
    "\n",
    "def main(file_path):\n",
    "    \"\"\"Função principal para execução completa sem TA-Lib\"\"\"\n",
    "    # 1. Carregar dados\n",
    "    print(\"Carregando dados...\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 2. Preparar target\n",
    "    print(\"\\nPreparando target...\")\n",
    "    df = preparar_target(df)\n",
    "    \n",
    "    # 3. Extrair features\n",
    "    print(\"\\nExtraindo features...\")\n",
    "    feature_extractor = FeatureExtractor()\n",
    "    df_features = feature_extractor.transform(df)\n",
    "    \n",
    "    # 4. Selecionar dados finais\n",
    "    X = df_features[feature_extractor.features_to_use]\n",
    "    y = df_features['retorno_futuro']\n",
    "    \n",
    "    # 5. Limpeza final\n",
    "    print(\"\\nLimpando dados...\")\n",
    "    X_clean, y_clean = clean_data(X, y)\n",
    "    \n",
    "    print(f\"\\nShape final dos dados: {X_clean.shape}\")\n",
    "    print(f\"Distribuição do target:\\n{y_clean.describe()}\")\n",
    "    \n",
    "    # 6. Avaliar modelo\n",
    "    print(\"\\nAvaliando modelo...\")\n",
    "    scores = avaliar_modelo(X_clean, y_clean)\n",
    "    \n",
    "    # 7. Treinar modelo final\n",
    "    print(\"\\nTreinando modelo final...\")\n",
    "    modelo = criar_pipeline()\n",
    "    modelo.fit(X_clean, y_clean)\n",
    "    \n",
    "    # 8. Visualizar importância das features\n",
    "    plot_feature_importance(modelo, feature_extractor.features_to_use)\n",
    "    \n",
    "    return modelo, X_clean, y_clean\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Executar pipeline completo sem TA-Lib\n",
    "    modelo_final, X_final, y_final = main(\"semanal2021-2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados...\n",
      "\n",
      "Preparando target...\n",
      "\n",
      "Extraindo features...\n",
      "\n",
      "Limpando dados...\n",
      "\n",
      "Dados finais: 90748 observações\n",
      "Features: 12 variáveis\n",
      "\n",
      "Treinando XGBoost com validação temporal...\n",
      "Fold 1: R² = 0.2087 | Melhor iteração: 35\n",
      "Fold 2: R² = 0.2439 | Melhor iteração: 70\n",
      "Fold 3: R² = 0.2336 | Melhor iteração: 40\n",
      "\n",
      "R² Médio: 0.2287 (±0.0148)\n",
      "\n",
      "Treinando modelo final...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo XGBoost treinado com sucesso!\n",
      "Exemplo de previsão para a primeira amostra: 0.1103\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Classe para extração avançada de features\"\"\"\n",
    "    def __init__(self):\n",
    "        self.features_to_use = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Garantir ordenação correta\n",
    "        if 'data_pregao' in df.columns:\n",
    "            df['data_pregao'] = pd.to_datetime(df['data_pregao'])\n",
    "            df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "        \n",
    "        # Grupo para cálculos\n",
    "        gb = df.groupby('cod_negociacao')['preco_fechamento']\n",
    "        \n",
    "        # 1. Médias móveis e volatilidade\n",
    "        for window in [4, 8, 12, 26]:\n",
    "            df[f'media_{window}w'] = gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "            df[f'vol_{window}w'] = gb.rolling(window=window).std().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # 2. Retornos protegidos contra divisão por zero\n",
    "        def safe_return(current, past, min_price=0.01):\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                return np.where(\n",
    "                    (past > min_price) & (current > min_price),\n",
    "                    (current - past) / past,\n",
    "                    np.nan\n",
    "                )\n",
    "        \n",
    "        for weeks, periods in [(1,0), (4,3), (12,11), (26,25)]:\n",
    "            preco_passado = gb.shift(periods)\n",
    "            df[f'retorno_{weeks}w'] = safe_return(df['preco_fechamento'], preco_passado)\n",
    "        \n",
    "        # 3. RSI manual (sem TA-Lib)\n",
    "        def calculate_rsi(series, window=14):\n",
    "            delta = series.diff()\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "            \n",
    "            avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
    "            avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
    "            \n",
    "            rs = avg_gain / avg_loss.replace(0, np.nan)\n",
    "            return 100 - (100 / (1 + rs.replace(np.inf, 100)))\n",
    "        \n",
    "        df['rsi_14'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(calculate_rsi)\n",
    "        \n",
    "        # 4. Features temporais\n",
    "        for lag in [1, 2, 3, 4]:\n",
    "            df[f'retorno_lag_{lag}w'] = df.groupby('cod_negociacao')['retorno_1w'].shift(lag)\n",
    "        \n",
    "        df['ema_12'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "            lambda x: x.ewm(span=12).mean()\n",
    "        )\n",
    "        \n",
    "        # 5. Features de volume\n",
    "        if 'volume' in df.columns:\n",
    "            vol_gb = df.groupby('cod_negociacao')['volume']\n",
    "            for window in [4, 12]:\n",
    "                df[f'volume_medio_{window}w'] = vol_gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # Definir features a serem usadas\n",
    "        self.features_to_use = [\n",
    "            'media_4w', 'media_12w', 'vol_4w', 'vol_12w',\n",
    "            'retorno_1w', 'retorno_4w', 'retorno_12w',\n",
    "            'retorno_lag_1w', 'retorno_lag_2w',\n",
    "            'volume_medio_4w', 'ema_12', 'rsi_14'\n",
    "        ]\n",
    "        \n",
    "        return df\n",
    "\n",
    "def preparar_target(df):\n",
    "    \"\"\"Prepara o target com tratamento robusto\"\"\"\n",
    "    df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "    \n",
    "    # Calcular retorno futuro de 52 semanas\n",
    "    df['retorno_futuro'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "        lambda x: x.pct_change(periods=52)\n",
    "    )\n",
    "    \n",
    "    # Remover outliers extremos\n",
    "    if 'retorno_futuro' in df.columns:\n",
    "        lower = df['retorno_futuro'].quantile(0.01)\n",
    "        upper = df['retorno_futuro'].quantile(0.99)\n",
    "        df['retorno_futuro'] = df['retorno_futuro'].clip(lower, upper)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_data(X, y):\n",
    "    \"\"\"Limpeza final dos dados\"\"\"\n",
    "    data = X.join(y)\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.dropna()\n",
    "    return data.drop('retorno_futuro', axis=1), data['retorno_futuro']\n",
    "\n",
    "def criar_pipeline_xgb():\n",
    "    \"\"\"Pipeline com XGBoost otimizado\"\"\"\n",
    "    return Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', XGBRegressor(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            eval_metric='rmse'\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "def treinar_avaliar_xgb(X, y):\n",
    "    \"\"\"Treinamento e avaliação personalizada com validação temporal\"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    scores = []\n",
    "    modelos = []\n",
    "    \n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Criar e treinar modelo\n",
    "        xgb = XGBRegressor(\n",
    "            n_estimators=500,  # Número maior pois usamos early stopping\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            early_stopping_rounds=20,\n",
    "            eval_metric='rmse'\n",
    "        )\n",
    "        \n",
    "        # Treinar com early stopping\n",
    "        xgb.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Avaliar\n",
    "        y_pred = xgb.predict(X_val)\n",
    "        score = r2_score(y_val, y_pred)\n",
    "        scores.append(score)\n",
    "        modelos.append(xgb)\n",
    "        \n",
    "        print(f\"Fold {len(scores)}: R² = {score:.4f} | Melhor iteração: {xgb.best_iteration}\")\n",
    "    \n",
    "    print(f\"\\nR² Médio: {np.mean(scores):.4f} (±{np.std(scores):.4f})\")\n",
    "    return modelos, scores\n",
    "\n",
    "def plot_xgb_importance(modelo, feature_names):\n",
    "    \"\"\"Visualização da importância das features no XGBoost\"\"\"\n",
    "    importances = modelo.feature_importances_\n",
    "    \n",
    "    # Cria DataFrame para melhor visualização\n",
    "    feat_imp = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance')\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(feat_imp)), feat_imp['Importance'], align='center')\n",
    "    plt.yticks(range(len(feat_imp)), feat_imp['Feature'])\n",
    "    plt.title('Importância das Features - XGBoost')\n",
    "    plt.xlabel('Importância Relativa')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main(file_path):\n",
    "    \"\"\"Função principal\"\"\"\n",
    "    try:\n",
    "        # 1. Carregar dados\n",
    "        print(\"Carregando dados...\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # 2. Preparar target\n",
    "        print(\"\\nPreparando target...\")\n",
    "        df = preparar_target(df)\n",
    "        \n",
    "        # 3. Extrair features\n",
    "        print(\"\\nExtraindo features...\")\n",
    "        feature_extractor = FeatureExtractor()\n",
    "        df_features = feature_extractor.transform(df)\n",
    "        \n",
    "        # 4. Selecionar dados finais\n",
    "        X = df_features[feature_extractor.features_to_use]\n",
    "        y = df_features['retorno_futuro']\n",
    "        \n",
    "        # 5. Limpeza final\n",
    "        print(\"\\nLimpando dados...\")\n",
    "        X_clean, y_clean = clean_data(X, y)\n",
    "        \n",
    "        print(f\"\\nDados finais: {X_clean.shape[0]} observações\")\n",
    "        print(f\"Features: {X_clean.shape[1]} variáveis\")\n",
    "        \n",
    "        # 6. Treinar e avaliar\n",
    "        print(\"\\nTreinando XGBoost com validação temporal...\")\n",
    "        modelos, scores = treinar_avaliar_xgb(X_clean, y_clean)\n",
    "        \n",
    "        # 7. Treinar modelo final com todos os dados\n",
    "        print(\"\\nTreinando modelo final...\")\n",
    "        modelo_final = XGBRegressor(\n",
    "            n_estimators=int(np.mean([m.best_iteration for m in modelos])) + 20,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        modelo_final.fit(X_clean, y_clean)\n",
    "        \n",
    "        # 8. Visualizar importância\n",
    "        plot_xgb_importance(modelo_final, feature_extractor.features_to_use)\n",
    "        \n",
    "        return modelo_final, X_clean, y_clean\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nErro: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Executar pipeline\n",
    "    modelo_xgb, X_data, y_data = main(\"semanal2021-2022.csv\")\n",
    "    \n",
    "    if modelo_xgb is not None:\n",
    "        print(\"\\nModelo XGBoost treinado com sucesso!\")\n",
    "        # Exemplo de previsão\n",
    "        sample_pred = modelo_xgb.predict(X_data.head(1))\n",
    "        print(f\"Exemplo de previsão para a primeira amostra: {sample_pred[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados...\n",
      "\n",
      "Preparando target...\n",
      "\n",
      "Extraindo features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Colaborador\\AppData\\Local\\Temp\\ipykernel_21860\\2927633753.py:89: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df['media_4w_change'] = df.groupby('cod_negociacao')['media_4w'].pct_change()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selecionando dados finais...\n",
      "\n",
      "Limpando dados...\n",
      "Erro na limpeza dos dados: Coluna alvo perdida durante a limpeza\n",
      "\n",
      "Dados preparados: 1277649 amostras, 16 features\n",
      "\n",
      "Treinando XGBoost com validação temporal...\n",
      "\n",
      "Erro durante a execução: [22:51:23] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\data.cc:550: Check failed: valid: Label contains NaN, infinity or a value too large.\n",
      "\n",
      "ERRO NO PROCESSO PRINCIPAL: [22:51:23] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\data.cc:550: Check failed: valid: Label contains NaN, infinity or a value too large.\n",
      "Verifique:\n",
      "- Se o arquivo CSV tem as colunas esperadas\n",
      "- Se há dados suficientes para calcular retornos de 52 semanas\n",
      "- Se há valores válidos nos preços de fechamento\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import r2_score\n",
    "from xgboost.callback import EarlyStopping\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Classe aprimorada para extração de features com novas métricas\"\"\"\n",
    "    def __init__(self):\n",
    "        self.features_to_use = []\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Garantir ordenação correta\n",
    "        if 'data_pregao' in df.columns:\n",
    "            df['data_pregao'] = pd.to_datetime(df['data_pregao'])\n",
    "            df = df.sort_values(['cod_negociacao', 'data_pregao'])\n",
    "        \n",
    "        # Grupo para cálculos\n",
    "        gb = df.groupby('cod_negociacao')['preco_fechamento']\n",
    "        \n",
    "        # 1. Features básicas (mantendo as mais importantes)\n",
    "        for window in [4, 12, 26]:  # Removida média de 8 semanas\n",
    "            df[f'media_{window}w'] = gb.rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "            df[f'vol_{window}w'] = gb.rolling(window=window).std().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # 2. Retornos protegidos contra divisão por zero\n",
    "        def safe_return(current, past, min_price=0.01):\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                return np.where(\n",
    "                    (past > min_price) & (current > min_price),\n",
    "                    (current - past) / past,\n",
    "                    np.nan\n",
    "                )\n",
    "        \n",
    "        for weeks, periods in [(1,0), (4,3), (12,11)]:  # Removido retorno de 26 semanas\n",
    "            preco_passado = gb.shift(periods)\n",
    "            df[f'retorno_{weeks}w'] = safe_return(df['preco_fechamento'], preco_passado)\n",
    "        \n",
    "        # 3. RSI manual aprimorado\n",
    "        def calculate_rsi(series, window=14):\n",
    "            delta = series.diff()\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "            \n",
    "            avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
    "            avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
    "            \n",
    "            rs = avg_gain / avg_loss.replace(0, np.nan)\n",
    "            return 100 - (100 / (1 + rs.replace(np.inf, 100)))\n",
    "        \n",
    "        df['rsi_14'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(calculate_rsi)\n",
    "        \n",
    "        # 4. Features temporais (mantendo apenas lags mais relevantes)\n",
    "        for lag in [1, 2]:  # Removido lags 3 e 4\n",
    "            df[f'retorno_lag_{lag}w'] = df.groupby('cod_negociacao')['retorno_1w'].shift(lag)\n",
    "        \n",
    "        df['ema_12'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "            lambda x: x.ewm(span=12).mean()\n",
    "        )\n",
    "        \n",
    "        # 5. Features de volume (apenas média de 4 semanas)\n",
    "        if 'volume' in df.columns:\n",
    "            vol_gb = df.groupby('cod_negociacao')['volume']\n",
    "            df['volume_medio_4w'] = vol_gb.rolling(window=4).mean().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # 6. NOVAS FEATURES BASEADAS NA ANÁLISE DE IMPORTÂNCIA\n",
    "        # Interação entre features importantes\n",
    "        df['rsi_media4w'] = df['rsi_14'] * df['media_4w']\n",
    "        df['ret12w_vol12w'] = df['retorno_12w'] * df['vol_12w']\n",
    "        \n",
    "        # Momentum aprimorado\n",
    "        df['momentum_4_12'] = df['retorno_4w'] - df['retorno_12w']\n",
    "        \n",
    "        # Razão de volatilidade\n",
    "        df['vol_ratio'] = df['vol_4w'] / (df['vol_12w'] + 1e-6)\n",
    "        \n",
    "        # Mudança percentual na média móvel\n",
    "        df['media_4w_change'] = df.groupby('cod_negociacao')['media_4w'].pct_change()\n",
    "        \n",
    "        # Definir features a serem usadas (focando nas mais importantes)\n",
    "        self.features_to_use = [\n",
    "            'rsi_14', 'retorno_12w', 'media_4w', 'media_12w', 'ema_12',\n",
    "            'vol_12w', 'retorno_4w', 'vol_4w', 'volume_medio_4w',\n",
    "            'retorno_lag_1w', 'retorno_lag_2w',\n",
    "            # Novas features\n",
    "            'rsi_media4w', 'ret12w_vol12w', 'momentum_4_12', \n",
    "            'vol_ratio', 'media_4w_change'\n",
    "        ]\n",
    "        \n",
    "        return df\n",
    "\n",
    "def preparar_target(df):\n",
    "    \"\"\"Prepara o target com verificações adicionais\"\"\"\n",
    "    try:\n",
    "        # Verificar colunas necessárias\n",
    "        if 'cod_negociacao' not in df.columns or 'preco_fechamento' not in df.columns:\n",
    "            raise ValueError(\"Colunas necessárias não encontradas\")\n",
    "        \n",
    "        # Ordenar dados\n",
    "        sort_cols = ['cod_negociacao']\n",
    "        if 'data_pregao' in df.columns:\n",
    "            sort_cols.append('data_pregao')\n",
    "            df['data_pregao'] = pd.to_datetime(df['data_pregao'])\n",
    "        \n",
    "        df = df.sort_values(sort_cols)\n",
    "        \n",
    "        # Calcular retorno futuro com verificação\n",
    "        if len(df) < 52:\n",
    "            raise ValueError(\"Dados insuficientes para calcular retorno de 52 semanas\")\n",
    "        \n",
    "        df['retorno_futuro'] = df.groupby('cod_negociacao')['preco_fechamento'].transform(\n",
    "            lambda x: x.pct_change(periods=52)\n",
    "        )\n",
    "        \n",
    "        # Verificar se o cálculo foi bem-sucedido\n",
    "        if df['retorno_futuro'].isna().all():\n",
    "            raise ValueError(\"Falha no cálculo do retorno futuro - verifique os dados\")\n",
    "        \n",
    "        # Tratar outliers de forma mais segura\n",
    "        if 'retorno_futuro' in df.columns:\n",
    "            valid_returns = df['retorno_futuro'].dropna()\n",
    "            if len(valid_returns) > 0:\n",
    "                lower = valid_returns.quantile(0.05)\n",
    "                upper = valid_returns.quantile(0.95)\n",
    "                df['retorno_futuro'] = df['retorno_futuro'].clip(lower, upper)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao preparar target: {str(e)}\")\n",
    "        # Retornar DataFrame original sem a coluna de retorno se houver erro\n",
    "        if 'retorno_futuro' in df.columns:\n",
    "            df = df.drop(columns=['retorno_futuro'])\n",
    "        return df\n",
    "\n",
    "\n",
    "def clean_data(X, y):\n",
    "    \"\"\"Limpeza final dos dados com tratamento robusto para coluna faltante\"\"\"\n",
    "    try:\n",
    "        # Juntar X e y garantindo que ambos são DataFrames/Series\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.to_frame(name='retorno_futuro')\n",
    "        \n",
    "        data = X.join(y)\n",
    "        \n",
    "        # Verificar se a coluna existe antes de tentar remover\n",
    "        if 'retorno_futuro' not in data.columns:\n",
    "            raise ValueError(\"Coluna 'retorno_futuro' não encontrada nos dados\")\n",
    "        \n",
    "        # Substituir infinitos e limpar NAs\n",
    "        data = data.replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # Remover colunas com muitos NAs (opcional)\n",
    "        data = data.dropna(axis=1, thresh=0.7*len(data))\n",
    "        \n",
    "        # Verificar novamente se a coluna alvo existe após limpeza\n",
    "        if 'retorno_futuro' not in data.columns:\n",
    "            raise ValueError(\"Coluna alvo perdida durante a limpeza\")\n",
    "        \n",
    "        # Separar features e target\n",
    "        X_clean = data.drop(columns=['retorno_futuro'])\n",
    "        y_clean = data['retorno_futuro']\n",
    "        \n",
    "        return X_clean, y_clean\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na limpeza dos dados: {str(e)}\")\n",
    "        # Retornar dados originais em caso de erro (ou tratar como preferir)\n",
    "        return X, y\n",
    "\n",
    "def criar_pipeline_xgb():\n",
    "    \"\"\"Pipeline com XGBoost otimizado\"\"\"\n",
    "    return Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', XGBRegressor(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.03,  # Taxa de aprendizado reduzida\n",
    "            max_depth=5,         # Profundidade reduzida\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.7,\n",
    "            gamma=0.1,           # Regularização adicional\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=0.1,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            eval_metric='rmse',\n",
    "            early_stopping_rounds=15\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "def treinar_avaliar_xgb(X, y):\n",
    "    \"\"\"Treinamento e avaliação personalizada com validação temporal\"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=4)  # Mais folds para validação\n",
    "    scores = []\n",
    "    best_iterations = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Modelo com early stopping\n",
    "        xgb = criar_pipeline_xgb()\n",
    "        xgb.fit(\n",
    "            X_train, y_train,\n",
    "            model__eval_set=[(X_val, y_val)],\n",
    "            model__verbose=0\n",
    "        )\n",
    "        \n",
    "        # Avaliação\n",
    "        score = xgb.score(X_val, y_val)\n",
    "        scores.append(score)\n",
    "        best_iterations.append(xgb.named_steps['model'].best_iteration)\n",
    "        \n",
    "        print(f\"Fold {fold}: R² = {score:.4f} | Melhor iteração: {xgb.named_steps['model'].best_iteration}\")\n",
    "    \n",
    "    print(f\"\\nPerformance média: R² = {np.mean(scores):.4f} (±{np.std(scores):.4f})\")\n",
    "    return scores, best_iterations\n",
    "\n",
    "def plot_xgb_importance(modelo, feature_names, top_n=15):\n",
    "    \"\"\"Visualização da importância das features no XGBoost\"\"\"\n",
    "    importances = modelo.named_steps['model'].feature_importances_\n",
    "    \n",
    "    # Criar DataFrame e selecionar top features\n",
    "    feat_imp = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False).head(top_n)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(feat_imp)), feat_imp['Importance'], align='center')\n",
    "    plt.yticks(range(len(feat_imp)), feat_imp['Feature'])\n",
    "    plt.title(f'Top {top_n} Features - XGBoost')\n",
    "    plt.xlabel('Importância Relativa')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main(file_path):\n",
    "    \"\"\"Função principal aprimorada\"\"\"\n",
    "    try:\n",
    "        print(\"Carregando dados...\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        print(\"\\nPreparando target...\")\n",
    "        df = preparar_target(df)\n",
    "        \n",
    "        # Verificar se o target foi criado com sucesso\n",
    "        if 'retorno_futuro' not in df.columns:\n",
    "            raise ValueError(\"Não foi possível criar a variável target 'retorno_futuro'\")\n",
    "        \n",
    "        print(\"\\nExtraindo features...\")\n",
    "        feature_extractor = FeatureExtractor()\n",
    "        df_features = feature_extractor.transform(df)\n",
    "        \n",
    "        # Verificar features extraídas\n",
    "        if not feature_extractor.features_to_use:\n",
    "            raise ValueError(\"Nenhuma feature foi extraída - verifique os dados de entrada\")\n",
    "        \n",
    "        print(\"\\nSelecionando dados finais...\")\n",
    "        X = df_features[feature_extractor.features_to_use]\n",
    "        y = df_features['retorno_futuro']\n",
    "        \n",
    "        print(\"\\nLimpando dados...\")\n",
    "        X_clean, y_clean = clean_data(X, y)\n",
    "        \n",
    "        # Verificação final dos dados\n",
    "        if len(X_clean) == 0 or len(y_clean) == 0:\n",
    "            raise ValueError(\"Dados limpos estão vazios - verifique o processo de limpeza\")\n",
    "        \n",
    "        print(f\"\\nDados preparados: {X_clean.shape[0]} amostras, {X_clean.shape[1]} features\")\n",
    "        \n",
    "        # 4. Treinar e avaliar\n",
    "        print(\"\\nTreinando XGBoost com validação temporal...\")\n",
    "        scores, best_iterations = treinar_avaliar_xgb(X_clean, y_clean)\n",
    "        \n",
    "        # 5. Treinar modelo final\n",
    "        print(\"\\nTreinando modelo final...\")\n",
    "        best_n_estimators = int(np.mean(best_iterations)) + 20  # Margem de segurança\n",
    "        \n",
    "        modelo_final = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', XGBRegressor(\n",
    "                n_estimators=best_n_estimators,\n",
    "                learning_rate=0.03,\n",
    "                max_depth=5,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.7,\n",
    "                gamma=0.1,\n",
    "                reg_alpha=0.1,\n",
    "                reg_lambda=0.1,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        modelo_final.fit(X_clean, y_clean)\n",
    "        \n",
    "        # 6. Avaliar e mostrar resultados\n",
    "        final_score = modelo_final.score(X_clean, y_clean)\n",
    "        print(f\"\\nPerformance no conjunto completo: R² = {final_score:.4f}\")\n",
    "        \n",
    "        # 7. Visualizar importância\n",
    "        plot_xgb_importance(modelo_final, feature_extractor.features_to_use)\n",
    "        \n",
    "        # 8. Exemplo de previsão\n",
    "        sample_pred = modelo_final.predict(X_clean.head(1))\n",
    "        print(f\"\\nExemplo de previsão: {sample_pred[0]:.4f}\")\n",
    "        \n",
    "        return modelo_final, X_clean, y_clean\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nErro durante a execução: {str(e)}\")\n",
    "        print(f\"\\nERRO NO PROCESSO PRINCIPAL: {str(e)}\")\n",
    "        print(\"Verifique:\")\n",
    "        print(\"- Se o arquivo CSV tem as colunas esperadas\")\n",
    "        print(\"- Se há dados suficientes para calcular retornos de 52 semanas\")\n",
    "        print(\"- Se há valores válidos nos preços de fechamento\")\n",
    "        return None, None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Executar pipeline completo\n",
    "    modelo_xgb, X_data, y_data = main(\"semanal2021-2022.csv\")\n",
    "    \n",
    "    if modelo_xgb is not None:\n",
    "        print(\"\\nProcesso concluído com sucesso!\")\n",
    "        # Opcional: Salvar modelo\n",
    "        # import joblib\n",
    "        # joblib.dump(modelo_xgb, 'modelo_xgb_final.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
